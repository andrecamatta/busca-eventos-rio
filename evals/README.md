# Sistema de Evals - Busca de Eventos

Sistema de avaliaÃ§Ã£o automatizada para validar se as diferentes fases do projeto estÃ£o atingindo suas expectativas.

## Estrutura

```
evals/
  __init__.py
  eval_search.py      # Eval da FASE 1 (Busca Perplexity)
  README.md           # Este arquivo
```

---

## eval_search.py - FASE 1: Busca com Perplexity

Avalia se a busca do Perplexity estÃ¡ retornando eventos conforme as expectativas definidas nos prompts.

### Expectativas Avaliadas

#### Eventos Gerais (por categoria)
- **Jazz**: 8-12 eventos
- **Teatro-ComÃ©dia**: 8-12 eventos
- **Outdoor-FimDeSemana**: 8-12 eventos

#### Eventos de Venues EspecÃ­ficos
- **Casa do Choro**: 3-5 eventos (mÃ­nimo)
- **Sala CecÃ­lia Meirelles**: 3-5 eventos (mÃ­nimo)
- **Teatro Municipal do Rio de Janeiro**: 3-5 eventos (mÃ­nimo)

#### Completude dos Campos (obrigatÃ³rios)
- Data vÃ¡lida (formato DD/MM/YYYY)
- HorÃ¡rio
- Local completo
- DescriÃ§Ã£o
- Link (opcional, apenas informativo)

### Uso

```bash
# Rodar eval bÃ¡sico
python evals/eval_search.py

# Especificar arquivo de output
python evals/eval_search.py --output output/structured_events.json

# Ajustar threshold de aprovaÃ§Ã£o
python evals/eval_search.py --threshold 70  # Default: 80
```

### Exit Codes

- `0`: PASS (score >= threshold)
- `1`: FAIL (score < threshold)
- `2`: ERRO (arquivo nÃ£o encontrado ou erro de execuÃ§Ã£o)

### Exemplo de SaÃ­da

```
======================================================================
EVAL: Busca Perplexity (FASE 1)
======================================================================
Arquivo: output/structured_events.json

ðŸ“Š EVENTOS GERAIS:
   Total: 9 eventos

   Jazz: 3/8-12 âš ï¸  BELOW
   Teatro-ComÃ©dia: 2/8-12 âš ï¸  BELOW
   Outdoor-FimDeSemana: 4/8-12 âš ï¸  BELOW

ðŸ›ï¸  EVENTOS DE VENUES:
   Total: 2 eventos

   Casa do Choro: 2/3-5 âš ï¸  BELOW
   Sala CecÃ­lia Meirelles: 0/3-5 âŒ CRITICAL
   Teatro Municipal do Rio de Janeiro: 0/3-5 âŒ CRITICAL

ðŸ“‹ COMPLETUDE DOS CAMPOS:

   âœ… Data (obrigatÃ³rio): 11/11 (100%)
   âœ… Horario (obrigatÃ³rio): 11/11 (100%)
   âœ… Local (obrigatÃ³rio): 11/11 (100%)
   âœ… Descricao (obrigatÃ³rio): 11/11 (100%)
   âœ… Link (opcional): 5/11 (45%)

   Data vÃ¡lida (formato): 11/11 (100%)

======================================================================
SCORE FINAL: 40% (4/10 critÃ©rios OK)
STATUS: âŒ FAIL
======================================================================
```

### InterpretaÃ§Ã£o dos Status

- `âœ… OK`: Dentro da meta esperada
- `âœ… ABOVE`: Acima da meta (ainda OK)
- `âš ï¸  BELOW`: Abaixo da meta (warning)
- `âŒ CRITICAL`: Categoria/venue sem eventos (crÃ­tico)

---

## Futuras ExpansÃµes

### eval_validation.py - FASE 2: ValidaÃ§Ã£o
- Avaliar acurÃ¡cia das validaÃ§Ãµes de data
- Medir falsos positivos/negativos
- Verificar detecÃ§Ã£o de divergÃªncias

### eval_enrichment.py - FASE 3: Enriquecimento
- Avaliar qualidade das descriÃ§Ãµes enriquecidas
- Verificar uso de contexto adicional

### eval_end_to_end.py - Sistema Completo
- MÃ©tricas de ponta a ponta
- ComparaÃ§Ã£o com ground truth (golden dataset)
- Precision, Recall, F1-score

---

## IntegraÃ§Ã£o CI/CD

```bash
# Executar todos os evals
python evals/eval_search.py || exit 1
# python evals/eval_validation.py || exit 1  # Futuro
# python evals/eval_end_to_end.py || exit 1  # Futuro
```

---

## Troubleshooting

### Erro: "Arquivo nÃ£o encontrado"
Certifique-se de que o sistema foi executado e gerou `output/structured_events.json`:
```bash
python main.py
```

### Score muito baixo
Isso indica que os prompts nÃ£o estÃ£o sendo seguidos adequadamente. PossÃ­veis causas:
- Perplexity retornando poucos eventos
- Categorias/venues sendo ignorados
- PerÃ­odo de busca muito restritivo

Verifique os logs do sistema e ajuste os prompts em `agents/search_agent.py`.
