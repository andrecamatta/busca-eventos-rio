"""Agente de busca de eventos."""

import asyncio
import json
import logging
from datetime import datetime
from typing import Any

from pydantic import ValidationError

from config import SEARCH_CONFIG, MAX_EVENTS_PER_VENUE
from models.event_models import ResultadoBuscaCategoria
from utils.agent_factory import AgentFactory
from utils.prompt_templates import PromptBuilder
from utils.prompt_loader import get_prompt_loader

logger = logging.getLogger(__name__)

# Prefixo para logs deste agente
LOG_PREFIX = "[SearchAgent] üîç"


class SearchAgent:
    """Agente respons√°vel por buscar eventos em m√∫ltiplas fontes."""

    def __init__(self):
        self.log_prefix = "[SearchAgent] üîç"

        # Carregar prompts do YAML
        self.prompt_loader = get_prompt_loader()
        logger.info(
            f"{self.log_prefix} üìã Prompts carregados: "
            f"{len(self.prompt_loader.get_all_categorias())} categorias, "
            f"{len(self.prompt_loader.get_all_venues())} venues"
        )

        # Agente de busca com Perplexity Sonar Pro (busca web em tempo real)
        self.search_agent = AgentFactory.create_agent(
            name="Event Search Agent",
            model_type="search",  # perplexity/sonar-pro
            description="Agente com busca web em tempo real para encontrar eventos culturais no Rio de Janeiro",
            instructions=[
                f"Voc√™ tem acesso √† busca web em tempo real. Use para encontrar eventos no Rio de Janeiro "
                f"entre {SEARCH_CONFIG['start_date'].strftime('%d/%m/%Y')} "
                f"e {SEARCH_CONFIG['end_date'].strftime('%d/%m/%Y')}",
                "Busque nas seguintes categorias:",
                "1. Shows de jazz no Rio (pr√≥ximas 3 semanas)",
                "2. Teatro com√©dia/stand-up no Rio (EXCETO eventos infantis)",
                "3. Eventos na Casa do Choro, Sala Cec√≠lia Meireles e Teatro Municipal",
                "4. Eventos ao ar livre em fim de semana no Rio",
                "Para cada evento, extrair: t√≠tulo, data completa, hor√°rio, local, valor/pre√ßo, link para compra de ingressos",
                "Buscar em sites como: Sympla, Eventbrite, Fever, TimeOut Rio, sites oficiais dos locais",
                "Retorne no formato JSON estruturado",
            ],
            markdown=True,
        )

    def _limit_events_per_venue(self, eventos_por_venue: dict[str, list[dict]]) -> dict[str, list[dict]]:
        """
        Limita eventos por venue ao m√°ximo definido em MAX_EVENTS_PER_VENUE.

        Crit√©rios de prioriza√ß√£o (em ordem):
        1. Eventos com link v√°lido (prioridade alta)
        2. Diversidade de datas (evita concentra√ß√£o no mesmo dia)
        3. Completude da descri√ß√£o (mais informa√ß√£o = melhor)
        4. Ordem cronol√≥gica (mais pr√≥ximos primeiro)
        """
        limited_events = {}

        for venue_name, eventos in eventos_por_venue.items():
            if len(eventos) <= MAX_EVENTS_PER_VENUE:
                limited_events[venue_name] = eventos
                continue

            # Calcular score para cada evento
            scored_events = []
            for evento in eventos:
                score = 0

                # 1. Link v√°lido = +100 pontos
                if evento.get("link_ingresso") and evento["link_ingresso"].lower() not in ("null", "none", ""):
                    score += 100

                # 2. Descri√ß√£o completa = +50 pontos (se > 50 palavras)
                descricao = evento.get("descricao", "") or ""
                if len(descricao.split()) > 50:
                    score += 50
                elif len(descricao.split()) > 20:
                    score += 25

                # 3. Data mais pr√≥xima = +1 a +30 pontos (inverso da posi√ß√£o)
                try:
                    data_str = evento.get("data", "")
                    if data_str:
                        # Parsear DD/MM/YYYY
                        data_evento = datetime.strptime(data_str, "%d/%m/%Y")
                        # Quanto mais pr√≥ximo, maior o score (max 30 pontos)
                        days_diff = (data_evento - datetime.now()).days
                        if days_diff >= 0:
                            # Normalizar: 0-21 dias ‚Üí 30-10 pontos
                            score += max(10, 30 - days_diff)
                except:
                    score += 15  # score neutro se data inv√°lida

                scored_events.append((score, evento))

            # Ordenar por score (maior primeiro)
            scored_events.sort(key=lambda x: x[0], reverse=True)

            # Selecionar top MAX_EVENTS_PER_VENUE
            selected = [evento for _, evento in scored_events[:MAX_EVENTS_PER_VENUE]]
            limited_events[venue_name] = selected

            # Log da redu√ß√£o
            if len(eventos) > MAX_EVENTS_PER_VENUE:
                logger.info(
                    f"üìä Venue '{venue_name}': {len(eventos)} eventos ‚Üí "
                    f"{len(selected)} selecionados (limite: {MAX_EVENTS_PER_VENUE})"
                )

        return limited_events

    def _normalize_venue_names(self, eventos_por_venue: dict[str, list[dict]]) -> dict[str, list[dict]]:
        """
        Consolida sub-venues em venues principais usando VENUE_ALIASES.

        Exemplo: "CCBB Teatro III" ‚Üí "CCBB Rio - Centro Cultural Banco do Brasil"
        """
        from config import VENUE_ALIASES

        normalized = {}
        consolidation_log = []

        for venue_name, eventos in eventos_por_venue.items():
            # Obter nome can√¥nico do venue
            canonical_name = VENUE_ALIASES.get(venue_name, venue_name)

            # Log de consolida√ß√£o se houve mudan√ßa
            if canonical_name != venue_name and len(eventos) > 0:
                consolidation_log.append(f"{venue_name} ‚Üí {canonical_name} ({len(eventos)} eventos)")

            # Merge eventos no venue can√¥nico
            if canonical_name not in normalized:
                normalized[canonical_name] = []
            normalized[canonical_name].extend(eventos)

        # Log consolida√ß√µes realizadas
        if consolidation_log:
            logger.info(f"üîó Consolida√ß√£o de venues:")
            for log_msg in consolidation_log:
                logger.info(f"   - {log_msg}")

        return normalized

    async def _run_micro_search(self, prompt: str, search_name: str) -> str:
        """Executa uma micro-search focada de forma ass√≠ncrona."""
        logger.info(f"   üîç Iniciando busca: {search_name}")

        def sync_search():
            try:
                response = self.search_agent.run(prompt)
                return response.content
            except Exception as e:
                logger.error(f"Erro na busca {search_name}: {e}")
                return "{}"

        result = await asyncio.to_thread(sync_search)
        logger.info(f"   ‚úì Busca conclu√≠da: {search_name}")
        return result

    def _build_focused_prompt(
        self,
        categoria: str,
        tipo_busca: str,  # "categoria" ou "venue"
        descricao: str,
        tipos_evento: list[str],
        palavras_chave: list[str],
        venues_sugeridos: list[str],
        instrucoes_especiais: str = "",
        start_date_str: str = "",
        end_date_str: str = "",
        month_year_str: str = "",
        month_str: str = "",
    ) -> str:
        """Constr√≥i prompt focado para uma √∫nica categoria ou venue (DRY)."""

        # Template comum para todos os prompts
        common_header = f"""Execute uma busca FOCADA e DETALHADA exclusivamente para: {categoria}

PER√çODO: {start_date_str} a {end_date_str}

üéØ FOCO EXCLUSIVO: {descricao}

ESTRAT√âGIA DE BUSCA:
"""

        # Se√ß√£o de tipos de evento
        tipos_section = "TIPOS DE EVENTO:\n"
        for tipo in tipos_evento:
            tipos_section += f"- {tipo}\n"

        # Se√ß√£o de palavras-chave
        keywords_section = "\nPALAVRAS-CHAVE PARA BUSCA:\n"
        for keyword in palavras_chave:
            keywords_section += f'- "{keyword}"\n'

        # Se√ß√£o de venues
        venues_section = "\nVENUES/LOCAIS PRIORIT√ÅRIOS:\n"
        for venue in venues_sugeridos:
            venues_section += f"- {venue}\n"

        # Fontes (comum para todos)
        sources_section = """
FONTES PARA BUSCAR:
- Sympla (sympla.com.br), Eventbrite (eventbrite.com.br), Fever (fever.com.br)
- Portais culturais: TimeOut Rio, Veja Rio, O Globo Cultura
- Sites oficiais dos venues e suas redes sociais (Instagram/Facebook)
- Bilheterias online oficiais dos locais
"""

        # Campos obrigat√≥rios (comum para todos)
        required_fields = """
INFORMA√á√ïES OBRIGAT√ìRIAS PARA CADA EVENTO:
- Nome completo do evento
- Data exata (formato DD/MM/YYYY)
- ‚ö†Ô∏è Hor√°rio de in√≠cio (HH:MM) - CR√çTICO: SEMPRE inclua o hor√°rio preciso
- Nome completo do local/venue + endere√ßo
- Pre√ßo (incluir meia-entrada se dispon√≠vel)
- Link para compra de ingressos (se dispon√≠vel)
- Descri√ß√£o detalhada: artistas, dura√ß√£o, p√∫blico-alvo

ATEN√á√ÉO ESPECIAL AO HOR√ÅRIO:
- O hor√°rio √© OBRIGAT√ìRIO (n√£o opcional)
- Formato: "19:00", "20:30", "21:00" (HH:MM)
- Se o site n√£o mostrar hor√°rio, busque em Instagram, Facebook, Sympla, Eventbrite
- NUNCA deixe hor√°rio em branco
"""

        # Formato de retorno (diferente para categoria vs venue)
        if tipo_busca == "categoria":
            return_format = f"""
FORMATO DE RETORNO:
{{
  "eventos": [
    {{
      "categoria": "{categoria}",
      "titulo": "Nome do evento",
      "data": "DD/MM/YYYY",
      "horario": "HH:MM",
      "local": "Nome completo + Endere√ßo",
      "preco": "Valor completo",
      "link_ingresso": "URL espec√≠fica ou null",
      "descricao": "Descri√ß√£o detalhada"
    }}
  ]
}}

IMPORTANTE:
- Busque o M√ÅXIMO de eventos poss√≠vel (objetivo: pelo menos 3 eventos)
- INCLUA TODOS os eventos que encontrar com data, hor√°rio, local e descri√ß√£o

‚ö†Ô∏è REGRAS CR√çTICAS PARA LINKS (leia com aten√ß√£o - links inv√°lidos ser√£o rejeitados):

1. N√ÉO RETORNE HOMEPAGES/SITES INSTITUCIONAIS:
   ‚ùå NUNCA retornar sites de ARTISTAS (ex: raphaelghanem.com.br, fabriciolins.com.br)
   ‚ùå NUNCA retornar homepages de VENUES (ex: casadochoro.com.br, teatroopuscitta.com.br)
   ‚ùå NUNCA retornar homepages de PLATAFORMAS (ex: sympla.com.br, ingresso.com)
   ‚ùå NUNCA retornar AGREGADORES gen√©ricos (ex: shazam.com/events, concerts50.com, songkick.com)
   ‚ùå NUNCA retornar p√°ginas de PROGRAMA√á√ÉO GERAL (ex: /programacao, /agenda, /calendario)

2. O link DEVE conter IDENTIFICADOR √öNICO do evento (um destes formatos):
   - ID num√©rico: /evento/nome-do-evento/123456
   - Slug com data: /evento-nome-18-11-2025
   - Hash alfanum√©rico: /shows/nome__abc123de/
   - Par√¢metro √∫nico: ?event_id=789 ou ?eve_cod=15246

3. PLATAFORMAS DE BUSCA (nesta ordem de prioridade):
   ü•á PRIORIT√ÅRIAS (sempre buscar primeiro):
   a) Sympla: sympla.com.br/evento/[nome]/[ID-numerico]
   b) Eventbrite: eventbrite.com.br/e/[nome]-tickets-[ID]
   c) Ticketmaster: ticketmaster.com.br/event/[ID]
   d) Fever: feverup.com/rio-de-janeiro/events/[nome-evento]

   ü•à SECUND√ÅRIAS (se priorit√°rias n√£o tiverem):
   e) Ingresso.com: ingresso.com/evento/[nome]/[ID]
   f) Bileto: bileto.sympla.com.br/event/[ID]

   ü•â VENUES ESPEC√çFICOS (apenas com p√°gina do evento):
   g) Blue Note: bluenoterio.com.br/shows/[nome-show]__[hash]/
   h) Sites oficiais com link ESPEC√çFICO do evento (N√ÉO homepage)

‚úÖ EXEMPLOS DE LINKS V√ÅLIDOS:
   ‚úÖ https://www.sympla.com.br/evento/raphael-ghanem-stand-up/2345678
   ‚úÖ https://www.eventbrite.com.br/e/quarteto-de-cordas-da-osb-tickets-987654321
   ‚úÖ https://bluenoterio.com.br/shows/irma-you-and-my-guitar__22hz624n/
   ‚úÖ https://www.ingresso.com/evento/caio-martins-segredo-revelado/15246

‚ùå EXEMPLOS DE LINKS INV√ÅLIDOS (NUNCA RETORNAR):
   HOMEPAGES E SITES INSTITUCIONAIS:
   ‚ùå https://raphaelghanem.com.br (site oficial do artista)
   ‚ùå https://casadochoro.com.br (homepage do venue)
   ‚ùå https://teatroopuscitta.com.br (homepage do teatro)
   ‚ùå https://www.sympla.com.br (homepage da plataforma)

   AGREGADORES GEN√âRICOS (n√£o vendem ingressos):
   ‚ùå https://shazam.com/events/rio-de-janeiro (apenas lista eventos)
   ‚ùå https://concerts50.com/brazil/rio-de-janeiro (agregador de terceiros)

   P√ÅGINAS DE CATEGORIA/BUSCA/LISTAGEM:
   ‚ùå https://www.ingresso.com/espetaculos/categorias/stand-up (categoria gen√©rica)
   ‚ùå https://www.sympla.com.br/eventos/rio-de-janeiro (listagem por cidade)
   ‚ùå https://eventbrite.com.br/d/brazil--rio-de-janeiro/events/ (listagem)
   ‚ùå https://bluenoterio.com.br/shows (listagem de todos os shows - falta ID espec√≠fico)

   PROGRAMA√á√ÉO GERAL DE VENUES:
   ‚ùå https://salaceliciameireles.rj.gov.br/programacao (calend√°rio mensal)
   ‚ùå https://casadochoro.com.br/programacao (agenda geral)

üìã CHECKLIST ANTES DE RETORNAR UM LINK:
   ‚úÖ O link cont√©m ID/identificador √∫nico? (num√©rico, slug, hash, ou par√¢metro)
   ‚úÖ O link √© de uma PLATAFORMA de venda (Sympla, Eventbrite, etc) OU p√°gina espec√≠fica do venue?
   ‚úÖ O link aponta para UMA p√°gina espec√≠fica de evento (n√£o listagem/categoria)?
   ‚úÖ O link N√ÉO √© homepage do artista/venue/plataforma?
   ‚úÖ O link N√ÉO √© de agregador gen√©rico (Shazam, Concerts50, etc)?

   SE TODAS AS RESPOSTAS FOREM ‚úÖ ‚Üí retornar link
   SE QUALQUER RESPOSTA FOR ‚ùå ‚Üí retornar null

4. SE N√ÉO ENCONTRAR link espec√≠fico:
   - Busque em TODAS as plataformas priorit√°rias (Sympla, Eventbrite, Ticketmaster, Fever)
   - Busque em plataformas secund√°rias (Ingresso.com, Bileto)
   - APENAS AP√ìS TENTAR TODAS AS FONTES: retorne null
   - N√ÉO retorne links gen√©ricos "por garantia" (null √© MELHOR que link inv√°lido)
"""
        else:  # venue
            return_format = f"""
ENCODING E CARACTERES ESPECIAIS:
- Usar UTF-8 encoding para TODOS os campos
- Caracteres acentuados s√£o PERMITIDOS e DEVEM ser escritos normalmente (ex: "Cec√≠lia", "m√∫sica", "s√°bado")
- N√ÉO usar escapes unicode (ex: \\u00ed) - escrever os caracteres acentuados diretamente
- A chave do JSON DEVE ser EXATAMENTE: "{categoria}" (preservar acentua√ß√£o se houver)

FORMATO DE RETORNO (use exatamente estes nomes de campos):
{{
  "{categoria}": [
    {{
      "titulo": "Nome do evento",
      "data": "DD/MM/YYYY",
      "horario": "HH:MM",
      "local": "{categoria} - Endere√ßo completo",
      "preco": "Valor completo",
      "link_ingresso": "URL espec√≠fica ou null",
      "descricao": "Descri√ß√£o detalhada"
    }}
  ]
}}

IMPORTANTE - NOMES DE CAMPOS:
- Use "horario" (n√£o "hora")
- Use "preco" (n√£o "pre√ßo")
- Use "link_ingresso" (n√£o "link")
- Use "descricao" (n√£o "descri√ß√£o")

REGRAS CR√çTICAS PARA JSON:
1. Comece DIRETAMENTE com {{ (sem markdown, sem textos, sem cabe√ßalhos antes)
2. Se usar markdown, use APENAS ```json no in√≠cio e ``` no final
3. Feche COMPLETAMENTE o JSON antes de qualquer texto explicativo
4. N√ÉO adicione nada DEPOIS do √∫ltimo }}
5. Caracteres especiais devem ser escritos normalmente (ex: "√†", "√£", "√ß", "√©", "√≠", "√≥", "√¥", "√µ", "√º")

OBJETIVO:
- Busque o M√ÅXIMO de eventos poss√≠vel (objetivo: pelo menos 1 evento)
- INCLUA TODOS os eventos que encontrar com data, hor√°rio, local e descri√ß√£o

‚ö†Ô∏è REGRAS CR√çTICAS PARA LINKS (leia com aten√ß√£o - links inv√°lidos ser√£o rejeitados):

1. N√ÉO RETORNE HOMEPAGES/SITES INSTITUCIONAIS:
   ‚ùå NUNCA retornar sites de ARTISTAS (ex: raphaelghanem.com.br, fabriciolins.com.br)
   ‚ùå NUNCA retornar homepages de VENUES (ex: casadochoro.com.br, teatroopuscitta.com.br)
   ‚ùå NUNCA retornar homepages de PLATAFORMAS (ex: sympla.com.br, ingresso.com)
   ‚ùå NUNCA retornar AGREGADORES gen√©ricos (ex: shazam.com/events, concerts50.com, songkick.com)
   ‚ùå NUNCA retornar p√°ginas de PROGRAMA√á√ÉO GERAL (ex: /programacao, /agenda, /calendario)

2. O link DEVE conter IDENTIFICADOR √öNICO do evento (um destes formatos):
   - ID num√©rico: /evento/nome-do-evento/123456
   - Slug com data: /evento-nome-18-11-2025
   - Hash alfanum√©rico: /shows/nome__abc123de/
   - Par√¢metro √∫nico: ?event_id=789 ou ?eve_cod=15246

3. PLATAFORMAS DE BUSCA (nesta ordem de prioridade):
   ü•á PRIORIT√ÅRIAS (sempre buscar primeiro):
   a) Sympla: sympla.com.br/evento/[nome]/[ID-numerico]
   b) Eventbrite: eventbrite.com.br/e/[nome]-tickets-[ID]
   c) Ticketmaster: ticketmaster.com.br/event/[ID]
   d) Fever: feverup.com/rio-de-janeiro/events/[nome-evento]

   ü•à SECUND√ÅRIAS (se priorit√°rias n√£o tiverem):
   e) Ingresso.com: ingresso.com/evento/[nome]/[ID]
   f) Bileto: bileto.sympla.com.br/event/[ID]

   ü•â VENUES ESPEC√çFICOS (apenas com p√°gina do evento):
   g) Blue Note: bluenoterio.com.br/shows/[nome-show]__[hash]/
   h) Sites oficiais com link ESPEC√çFICO do evento (N√ÉO homepage)

‚úÖ EXEMPLOS DE LINKS V√ÅLIDOS:
   ‚úÖ https://www.sympla.com.br/evento/raphael-ghanem-stand-up/2345678
   ‚úÖ https://www.eventbrite.com.br/e/quarteto-de-cordas-da-osb-tickets-987654321
   ‚úÖ https://bluenoterio.com.br/shows/irma-you-and-my-guitar__22hz624n/
   ‚úÖ https://www.ingresso.com/evento/caio-martins-segredo-revelado/15246

‚ùå EXEMPLOS DE LINKS INV√ÅLIDOS (NUNCA RETORNAR):
   HOMEPAGES E SITES INSTITUCIONAIS:
   ‚ùå https://raphaelghanem.com.br (site oficial do artista)
   ‚ùå https://casadochoro.com.br (homepage do venue)
   ‚ùå https://teatroopuscitta.com.br (homepage do teatro)
   ‚ùå https://www.sympla.com.br (homepage da plataforma)

   AGREGADORES GEN√âRICOS (n√£o vendem ingressos):
   ‚ùå https://shazam.com/events/rio-de-janeiro (apenas lista eventos)
   ‚ùå https://concerts50.com/brazil/rio-de-janeiro (agregador de terceiros)

   P√ÅGINAS DE CATEGORIA/BUSCA/LISTAGEM:
   ‚ùå https://www.ingresso.com/espetaculos/categorias/stand-up (categoria gen√©rica)
   ‚ùå https://www.sympla.com.br/eventos/rio-de-janeiro (listagem por cidade)
   ‚ùå https://eventbrite.com.br/d/brazil--rio-de-janeiro/events/ (listagem)
   ‚ùå https://bluenoterio.com.br/shows (listagem de todos os shows - falta ID espec√≠fico)

   PROGRAMA√á√ÉO GERAL DE VENUES:
   ‚ùå https://salaceliciameireles.rj.gov.br/programacao (calend√°rio mensal)
   ‚ùå https://casadochoro.com.br/programacao (agenda geral)

üìã CHECKLIST ANTES DE RETORNAR UM LINK:
   ‚úÖ O link cont√©m ID/identificador √∫nico? (num√©rico, slug, hash, ou par√¢metro)
   ‚úÖ O link √© de uma PLATAFORMA de venda (Sympla, Eventbrite, etc) OU p√°gina espec√≠fica do venue?
   ‚úÖ O link aponta para UMA p√°gina espec√≠fica de evento (n√£o listagem/categoria)?
   ‚úÖ O link N√ÉO √© homepage do artista/venue/plataforma?
   ‚úÖ O link N√ÉO √© de agregador gen√©rico (Shazam, Concerts50, etc)?

   SE TODAS AS RESPOSTAS FOREM ‚úÖ ‚Üí retornar link
   SE QUALQUER RESPOSTA FOR ‚ùå ‚Üí retornar null

4. SE N√ÉO ENCONTRAR link espec√≠fico:
   - Busque em TODAS as plataformas priorit√°rias (Sympla, Eventbrite, Ticketmaster, Fever)
   - Busque em plataformas secund√°rias (Ingresso.com, Bileto)
   - APENAS AP√ìS TENTAR TODAS AS FONTES: retorne null
   - N√ÉO retorne links gen√©ricos "por garantia" (null √© MELHOR que link inv√°lido)
"""

        # Montar prompt completo
        return (
            common_header
            + tipos_section
            + keywords_section
            + venues_section
            + sources_section
            + instrucoes_especiais
            + required_fields
            + return_format
        )

    def _build_prompt_from_config(self, config: dict, context: dict) -> str:
        """
        Constr√≥i prompt a partir de configura√ß√£o YAML.

        Args:
            config: Configura√ß√£o carregada do YAML (categoria ou venue)
            context: Contexto com vari√°veis de data (start_date_str, end_date_str, etc)

        Returns:
            Prompt completo formatado
        """
        # Nomes dos campos variam se √© categoria ou venue
        # Para categoria: venues_sugeridos
        # Para venue: pode n√£o ter venues_sugeridos (usar lista vazia)

        venues_list = config.get("venues_sugeridos", config.get("fontes_prioritarias", []))

        return self._build_focused_prompt(
            categoria=config["nome"],
            tipo_busca=config["tipo_busca"],
            descricao=config["descricao"],
            tipos_evento=config["tipos_evento"],
            palavras_chave=config["palavras_chave"],
            venues_sugeridos=venues_list if isinstance(venues_list, list) else [],
            instrucoes_especiais=config.get("instrucoes_especiais", ""),
            start_date_str=context["start_date_str"],
            end_date_str=context["end_date_str"],
            month_year_str=context["month_year_str"],
            month_str=context["month_str"]
        )

    async def search_all_sources(self) -> dict[str, Any]:
        """Busca eventos usando Perplexity Sonar Pro com 6 micro-searches focadas."""
        logger.info(f"{self.log_prefix} Iniciando busca de eventos com Perplexity Sonar Pro...")

        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # PRIORIDADE 1: SCRAPERS CUSTOMIZADOS (Blue Note + Sala Cec√≠lia Meireles)
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        logger.info(f"{self.log_prefix} üé´ Buscando eventos via scrapers customizados...")
        from utils.eventim_scraper import EventimScraper

        # Blue Note
        blue_note_scraped = EventimScraper.scrape_blue_note_events()
        if blue_note_scraped:
            logger.info(f"‚úì Encontrados {len(blue_note_scraped)} eventos Blue Note no Eventim")
        else:
            logger.warning("‚ö†Ô∏è  Nenhum evento Blue Note encontrado no scraper")

        # Sala Cec√≠lia Meireles
        cecilia_meireles_scraped = EventimScraper.scrape_cecilia_meireles_events()
        if cecilia_meireles_scraped:
            logger.info(f"‚úì Encontrados {len(cecilia_meireles_scraped)} eventos Sala Cec√≠lia Meireles")
        else:
            logger.warning("‚ö†Ô∏è  Nenhum evento Sala Cec√≠lia Meireles encontrado no scraper")

        # CCBB Rio
        ccbb_scraped = EventimScraper.scrape_ccbb_events()
        if ccbb_scraped:
            logger.info(f"‚úì Encontrados {len(ccbb_scraped)} eventos CCBB")
        else:
            logger.warning("‚ö†Ô∏è  Nenhum evento CCBB encontrado no scraper")

        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # CARREGAR PROMPTS DO YAML
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # Construir contexto de datas para interpola√ß√£o
        context = self.prompt_loader.build_context(
            SEARCH_CONFIG['start_date'],
            SEARCH_CONFIG['end_date']
        )

        logger.info(f"{self.log_prefix} Criando prompts a partir do YAML...")


        # Carregar configura√ß√µes de categorias e construir prompts
        categorias_ids = ["jazz", "comedia", "musica_classica", "outdoor", "cinema", "feira_gastronomica", "feira_artesanato"]
        prompts_categorias = {}

        for cat_id in categorias_ids:
            config = self.prompt_loader.get_categoria(cat_id, context)
            prompts_categorias[cat_id] = self._build_prompt_from_config(config, context)

        # Carregar configura√ß√µes de venues e construir prompts
        venues_ids = [
            "casa_choro", "sala_cecilia", "teatro_municipal", "artemis", "ccbb",
            "oi_futuro", "ims", "parque_lage", "ccjf", "mam_cinema",
            "theatro_net", "ccbb_teatro_cinema",
            "istituto_italiano", "maze_jazz", "teatro_leblon", "clube_jazz_rival", "estacao_net"
        ]
        prompts_venues = {}

        for venue_id in venues_ids:
            config = self.prompt_loader.get_venue(venue_id, context)
            prompts_venues[venue_id] = self._build_prompt_from_config(config, context)

        total_prompts = len(categorias_ids) + len(venues_ids)
        logger.info(f"{self.log_prefix} ‚úÖ {total_prompts} prompts criados com sucesso")

        try:
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # EXECU√á√ÉO PARALELA DAS MICRO-SEARCHES
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            logger.info(f"{self.log_prefix} Executando {total_prompts} micro-searches em paralelo...")

            # Executar todas as buscas em paralelo
            results = await asyncio.gather(
                self._run_micro_search(prompts_categorias["jazz"], "Jazz"),
                self._run_micro_search(prompts_categorias["comedia"], "Com√©dia"),
                self._run_micro_search(prompts_categorias["musica_classica"], "M√∫sica Cl√°ssica"),
                self._run_micro_search(prompts_categorias["outdoor"], "Outdoor/Parques"),
                self._run_micro_search(prompts_categorias["cinema"], "Cinema"),
                self._run_micro_search(prompts_categorias["feira_gastronomica"], "Feira Gastron√¥mica"),
                self._run_micro_search(prompts_categorias["feira_artesanato"], "Feira de Artesanato"),
                self._run_micro_search(prompts_venues["casa_choro"], "Casa do Choro"),
                self._run_micro_search(prompts_venues["sala_cecilia"], "Sala Cec√≠lia Meireles"),
                self._run_micro_search(prompts_venues["teatro_municipal"], "Teatro Municipal"),
                self._run_micro_search(prompts_venues["artemis"], "Artemis"),
                self._run_micro_search(prompts_venues["ccbb"], "CCBB Rio"),
                self._run_micro_search(prompts_venues["oi_futuro"], "Oi Futuro"),
                self._run_micro_search(prompts_venues["ims"], "IMS"),
                self._run_micro_search(prompts_venues["parque_lage"], "Parque Lage"),
                self._run_micro_search(prompts_venues["ccjf"], "CCJF"),
                self._run_micro_search(prompts_venues["mam_cinema"], "MAM Cinema"),
                self._run_micro_search(prompts_venues["theatro_net"], "Theatro Net Rio"),
                self._run_micro_search(prompts_venues["ccbb_teatro_cinema"], "CCBB Teatro/Cinema"),
                self._run_micro_search(prompts_venues["istituto_italiano"], "Istituto Italiano"),
                self._run_micro_search(prompts_venues["maze_jazz"], "Maze Jazz Club"),
                self._run_micro_search(prompts_venues["teatro_leblon"], "Teatro do Leblon"),
                self._run_micro_search(prompts_venues["clube_jazz_rival"], "Clube do Jazz/Rival"),
                self._run_micro_search(prompts_venues["estacao_net"], "Esta√ß√£o Net"),
            )
            # Desempacotar resultados
            (
                result_jazz,
                result_comedia,
                result_musica_classica,
                result_outdoor,
                result_cinema,
                result_feira_gastronomica,
                result_feira_artesanato,
                result_casa_choro,
                result_sala_cecilia,
                result_teatro_municipal,
                result_artemis,
                result_ccbb,
                result_oi_futuro,
                result_ims,
                result_parque_lage,
                result_ccjf,
                result_mam_cinema,
                result_theatro_net,
                result_ccbb_teatro_cinema,
                result_istituto_italiano,
                result_maze_jazz,
                result_teatro_leblon,
                result_clube_jazz_rival,
                result_estacao_net,
            ) = results

            logger.info(f"‚úì Todas as {total_prompts} micro-searches conclu√≠das")

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # MERGE INTELIGENTE DOS RESULTADOS COM PYDANTIC
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            logger.info("üîó Fazendo merge dos resultados...")

            # Helper function: Clean markdown from JSON
            def clean_json_from_markdown(text: str) -> str:
                """Remove markdown code blocks and extra text from JSON responses.

                Handles cases like:
                - # Eventos na Sala Cec√≠lia Meireles\n\nCom base na busca...\n\n```json\n{...}\n```
                - Plain JSON with preamble text
                - Multiple markdown blocks (uses last one)
                """
                if not text or text.strip() == "":
                    return ""

                import re

                # Remove leading/trailing whitespace
                text = text.strip()

                # STEP 1: Try to find JSON within markdown code blocks
                # Pattern: ```json ... ``` or ``` ... ```
                code_block_pattern = r'```(?:json)?\s*([\s\S]*?)\s*```'
                matches = re.findall(code_block_pattern, text)
                if matches:
                    # Use the last match (usually the complete JSON)
                    text = matches[-1].strip()

                # STEP 2: Remove ANYTHING before the first { or [
                # This handles preamble text like headers, explanations, etc.
                json_start_brace = text.find('{')
                json_start_bracket = text.find('[')

                # Find the earliest valid JSON start
                valid_starts = [pos for pos in [json_start_brace, json_start_bracket] if pos != -1]
                if valid_starts:
                    json_start = min(valid_starts)
                    text = text[json_start:]

                # STEP 3: Remove ANYTHING after the last } or ]
                # Find matching closing bracket
                if text.startswith('{'):
                    # Find the last } that matches the structure
                    depth = 0
                    for i, char in enumerate(text):
                        if char == '{':
                            depth += 1
                        elif char == '}':
                            depth -= 1
                            if depth == 0:
                                text = text[:i+1]
                                break
                elif text.startswith('['):
                    # Find the last ] that matches the structure
                    depth = 0
                    for i, char in enumerate(text):
                        if char == '[':
                            depth += 1
                        elif char == ']':
                            depth -= 1
                            if depth == 0:
                                text = text[:i+1]
                                break

                return text.strip()

            # Helper function: Parse categoria com Pydantic
            def safe_parse_categoria(result_str: str, search_name: str) -> list[dict]:
                """Parse categoria usando Pydantic validation."""
                try:
                    if not result_str or result_str.strip() == "":
                        logger.warning(f"‚ö†Ô∏è  Busca {search_name} retornou vazio")
                        return []
                    # Limpar markdown antes de parsear
                    clean_json = clean_json_from_markdown(result_str)
                    if not clean_json:
                        logger.warning(f"‚ö†Ô∏è  Busca {search_name} retornou JSON vazio ap√≥s limpeza")
                        return []
                    # Use Pydantic para validar e parsear
                    resultado = ResultadoBuscaCategoria.model_validate_json(clean_json)
                    logger.info(f"‚úì Busca {search_name}: {len(resultado.eventos)} eventos validados")
                    # Converter Pydantic models para dicts
                    return [evento.model_dump() for evento in resultado.eventos]
                except ValidationError as e:
                    logger.error(f"‚ùå Schema inv√°lido na busca {search_name}:")
                    for error in e.errors():
                        logger.error(f"   ‚Ä¢ {error['loc']}: {error['msg']}")
                    logger.error(f"   Conte√∫do (primeiros 200 chars): {result_str[:200]}")
                    return []
                except Exception as e:
                    logger.error(f"‚ùå Erro inesperado na busca {search_name}: {e}")
                    return []

            # Helper function: Parse venue (formato diferente, mant√©m dict)
            def safe_parse_venue(result_str: str, venue_name: str) -> list[dict]:
                """Parse venue usando JSON simples (formato: {venue_name: [eventos]}).

                Inclui fallback com normaliza√ß√£o unicode para lidar com acentua√ß√£o.
                """
                try:
                    import unicodedata

                    if not result_str or result_str.strip() == "":
                        logger.warning(f"‚ö†Ô∏è  Busca {venue_name} retornou vazio")
                        return []
                    # Limpar markdown antes de parsear
                    clean_json = clean_json_from_markdown(result_str)
                    if not clean_json:
                        logger.warning(f"‚ö†Ô∏è  Busca {venue_name} retornou JSON vazio ap√≥s limpeza")
                        return []
                    data = json.loads(clean_json)

                    # STEP 1: Tentar match exato primeiro
                    eventos = data.get(venue_name, [])

                    # STEP 2: Se n√£o encontrou, tentar com normaliza√ß√£o unicode (fallback)
                    if not eventos and venue_name:
                        # Normalizar nome do venue esperado (NFD = decompor acentos)
                        normalized_expected = unicodedata.normalize('NFD', venue_name)

                        # Tentar encontrar chave com normaliza√ß√£o
                        for key in data.keys():
                            normalized_key = unicodedata.normalize('NFD', key)
                            if normalized_key == normalized_expected:
                                eventos = data.get(key, [])
                                logger.info(
                                    f"‚öôÔ∏è  Fallback unicode: '{key}' ‚Üí '{venue_name}' "
                                    f"({len(eventos)} eventos)"
                                )
                                break

                    if eventos:
                        logger.info(f"‚úì Busca {venue_name}: {len(eventos)} eventos encontrados")
                    else:
                        logger.warning(f"‚ö†Ô∏è  Nenhum evento encontrado para {venue_name} (chaves dispon√≠veis: {list(data.keys())})")

                    return eventos
                except json.JSONDecodeError as e:
                    logger.error(f"‚ùå JSON inv√°lido na busca {venue_name}: {e}")
                    logger.error(f"   Conte√∫do (primeiros 200 chars): {result_str[:200]}")
                    return []

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # MERGE JAZZ: Scraper Blue Note TEM PRIORIDADE sobre Perplexity
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            eventos_jazz = []

            # PASSO 1: Adicionar eventos do SCRAPER primeiro (prioridade alta - links oficiais)
            if blue_note_scraped:
                logger.info(f"üé´ [PRIORIDADE] Adicionando {len(blue_note_scraped)} eventos Blue Note do scraper oficial...")
                for scraped_event in blue_note_scraped:
                    # Converter para formato EventoCategoria
                    jazz_event = {
                        "titulo": scraped_event["titulo"],
                        "data": scraped_event["data"],
                        "horario": scraped_event["horario"],
                        "local": "Blue Note Rio - Av. Atl√¢ntica, 1910, Copacabana, Rio de Janeiro",
                        "preco": "Consultar link",
                        "link_ingresso": scraped_event["link"],
                        "descricao": None,  # Ser√° enriquecido depois
                        "categoria": "Jazz"
                    }
                    eventos_jazz.append(jazz_event)
                    logger.debug(f"   ‚úì Scraper: {jazz_event['titulo']}")
                logger.info(f"‚úì {len(eventos_jazz)} eventos do scraper Blue Note adicionados")

            # PASSO 2: Adicionar eventos do PERPLEXITY como complemento (apenas n√£o-duplicatas)
            eventos_jazz_perplexity = safe_parse_categoria(result_jazz, "Jazz")
            logger.debug(f"Jazz parsed from Perplexity - {len(eventos_jazz_perplexity)} eventos")

            if eventos_jazz_perplexity:
                duplicatas_perplexity = 0
                for perplexity_event in eventos_jazz_perplexity:
                    # Verificar duplicata por t√≠tulo (case-insensitive)
                    if not any(e.get("titulo", "").lower() == perplexity_event.get("titulo", "").lower()
                               for e in eventos_jazz):
                        eventos_jazz.append(perplexity_event)
                        logger.debug(f"   ‚úì Perplexity: {perplexity_event.get('titulo')}")
                    else:
                        duplicatas_perplexity += 1
                        logger.debug(f"   ‚è≠Ô∏è  Duplicata do Perplexity ignorada (scraper tem prioridade): {perplexity_event.get('titulo')}")

                if duplicatas_perplexity > 0:
                    logger.info(f"‚è≠Ô∏è  {duplicatas_perplexity} duplicatas do Perplexity ignoradas (scraper tem prioridade)")

            logger.info(f"‚úì Total de eventos Jazz ap√≥s merge: {len(eventos_jazz)} eventos")

            eventos_comedia = safe_parse_categoria(result_comedia, "Com√©dia")
            logger.debug(f"Com√©dia parsed - {len(eventos_comedia)} eventos")

            eventos_musica_classica = safe_parse_categoria(result_musica_classica, "M√∫sica Cl√°ssica")
            logger.debug(f"M√∫sica Cl√°ssica parsed - {len(eventos_musica_classica)} eventos")

            eventos_outdoor = safe_parse_categoria(result_outdoor, "Outdoor/Parques")
            logger.debug(f"Outdoor/Parques parsed - {len(eventos_outdoor)} eventos")

            eventos_cinema = safe_parse_categoria(result_cinema, "Cinema")
            logger.debug(f"Cinema parsed - {len(eventos_cinema)} eventos")

            eventos_feira_gastronomica = safe_parse_categoria(result_feira_gastronomica, "Feira Gastron√¥mica")
            logger.debug(f"Feira Gastron√¥mica parsed - {len(eventos_feira_gastronomica)} eventos")

            eventos_feira_artesanato = safe_parse_categoria(result_feira_artesanato, "Feira de Artesanato")
            logger.debug(f"Feira de Artesanato parsed - {len(eventos_feira_artesanato)} eventos")

            # Merge eventos gerais (todas as 7 categorias)
            todos_eventos_gerais = (
                eventos_jazz +
                eventos_comedia +
                eventos_musica_classica +
                eventos_outdoor +
                eventos_cinema +
                eventos_feira_gastronomica +
                eventos_feira_artesanato
            )

            # Criar estrutura de eventos gerais
            eventos_gerais_merged = {"eventos": todos_eventos_gerais}

            # Parse eventos de venues
            eventos_casa_choro = safe_parse_venue(result_casa_choro, "Casa do Choro")
            logger.debug(f"Casa do Choro parsed - {len(eventos_casa_choro)} eventos")

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # MERGE SALA CEC√çLIA MEIRELES: Scraper TEM PRIORIDADE sobre Perplexity
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            eventos_sala_cecilia = []

            # PASSO 1: Adicionar eventos do SCRAPER primeiro (prioridade alta - links oficiais)
            if cecilia_meireles_scraped:
                logger.info(f"üéº [PRIORIDADE] Adicionando {len(cecilia_meireles_scraped)} eventos Sala Cec√≠lia Meireles do scraper oficial...")
                for scraped_event in cecilia_meireles_scraped:
                    # Converter para formato EventoVenue
                    cecilia_event = {
                        "titulo": scraped_event["titulo"],
                        "data": scraped_event["data"],
                        "horario": scraped_event["horario"],
                        "local": "Sala Cec√≠lia Meireles - Rua da Lapa, 47, Centro, Rio de Janeiro",
                        "preco": "Consultar link",
                        "link_ingresso": scraped_event["link"],
                        "descricao": None,  # Ser√° enriquecido depois
                        "venue": "Sala Cec√≠lia Meireles"
                    }
                    eventos_sala_cecilia.append(cecilia_event)
                    logger.debug(f"   ‚úì Scraper: {cecilia_event['titulo']}")
                logger.info(f"‚úì {len(eventos_sala_cecilia)} eventos do scraper Sala Cec√≠lia Meireles adicionados")

            # PASSO 2: Adicionar eventos do PERPLEXITY como complemento (apenas n√£o-duplicatas)
            eventos_sala_cecilia_perplexity = safe_parse_venue(result_sala_cecilia, "Sala Cec√≠lia Meireles")
            logger.debug(f"Sala Cec√≠lia Meireles parsed from Perplexity - {len(eventos_sala_cecilia_perplexity)} eventos")

            if eventos_sala_cecilia_perplexity:
                duplicatas_perplexity = 0
                for perplexity_event in eventos_sala_cecilia_perplexity:
                    # Verificar duplicata por t√≠tulo (case-insensitive)
                    if not any(e.get("titulo", "").lower() == perplexity_event.get("titulo", "").lower()
                               for e in eventos_sala_cecilia):
                        eventos_sala_cecilia.append(perplexity_event)
                        logger.debug(f"   ‚úì Perplexity: {perplexity_event.get('titulo')}")
                    else:
                        duplicatas_perplexity += 1
                        logger.debug(f"   ‚è≠Ô∏è  Duplicata do Perplexity ignorada (scraper tem prioridade): {perplexity_event.get('titulo')}")

                if duplicatas_perplexity > 0:
                    logger.info(f"‚è≠Ô∏è  {duplicatas_perplexity} duplicatas do Perplexity ignoradas (scraper tem prioridade)")

            logger.info(f"‚úì Total de eventos Sala Cec√≠lia Meireles ap√≥s merge: {len(eventos_sala_cecilia)} eventos")

            eventos_teatro_municipal = safe_parse_venue(result_teatro_municipal, "Teatro Municipal do Rio de Janeiro")
            logger.debug(f"Teatro Municipal parsed - {len(eventos_teatro_municipal)} eventos")

            eventos_artemis = safe_parse_venue(result_artemis, "Artemis - Torrefa√ß√£o Artesanal e Cafeteria")
            logger.debug(f"Artemis parsed - {len(eventos_artemis)} eventos")

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # MERGE CCBB: Scraper TEM PRIORIDADE sobre Perplexity
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            eventos_ccbb = []

            # PASSO 1: Adicionar eventos do SCRAPER primeiro (prioridade alta - links oficiais)
            if ccbb_scraped:
                logger.info(f"üé® [PRIORIDADE] Adicionando {len(ccbb_scraped)} eventos CCBB do scraper oficial...")
                for scraped_event in ccbb_scraped:
                    # Converter para formato EventoVenue
                    ccbb_event = {
                        "titulo": scraped_event["titulo"],
                        "data": scraped_event["data"],
                        "horario": scraped_event["horario"],
                        "local": "CCBB Rio - Centro Cultural Banco do Brasil - Rua Primeiro de Mar√ßo, 66, Centro, Rio de Janeiro",
                        "preco": "Consultar link",
                        "link_ingresso": scraped_event["link"],
                        "descricao": None,  # Ser√° enriquecido depois
                        "venue": "CCBB Rio - Centro Cultural Banco do Brasil"
                    }
                    eventos_ccbb.append(ccbb_event)
                    logger.debug(f"   ‚úì Scraper: {ccbb_event['titulo']}")
                logger.info(f"‚úì {len(eventos_ccbb)} eventos do scraper CCBB adicionados")

            # PASSO 2: Adicionar eventos do PERPLEXITY como complemento (apenas n√£o-duplicatas)
            eventos_ccbb_perplexity = safe_parse_venue(result_ccbb, "CCBB Rio - Centro Cultural Banco do Brasil")
            logger.debug(f"CCBB Rio parsed from Perplexity - {len(eventos_ccbb_perplexity)} eventos")

            if eventos_ccbb_perplexity:
                duplicatas_perplexity = 0
                for perplexity_event in eventos_ccbb_perplexity:
                    # Verificar duplicata por t√≠tulo (case-insensitive)
                    if not any(e.get("titulo", "").lower() == perplexity_event.get("titulo", "").lower()
                               for e in eventos_ccbb):
                        eventos_ccbb.append(perplexity_event)
                        logger.debug(f"   ‚úì Perplexity: {perplexity_event.get('titulo')}")
                    else:
                        duplicatas_perplexity += 1
                        logger.debug(f"   ‚è≠Ô∏è  Duplicata do Perplexity ignorada (scraper tem prioridade): {perplexity_event.get('titulo')}")

                if duplicatas_perplexity > 0:
                    logger.info(f"‚è≠Ô∏è  {duplicatas_perplexity} duplicatas do Perplexity ignoradas (scraper tem prioridade)")

            logger.info(f"‚úì Total de eventos CCBB ap√≥s merge: {len(eventos_ccbb)} eventos")

            eventos_oi_futuro = safe_parse_venue(result_oi_futuro, "Oi Futuro")
            logger.debug(f"Oi Futuro parsed - {len(eventos_oi_futuro)} eventos")

            eventos_ims = safe_parse_venue(result_ims, "IMS - Instituto Moreira Salles")
            logger.debug(f"IMS parsed - {len(eventos_ims)} eventos")

            eventos_parque_lage = safe_parse_venue(result_parque_lage, "Parque Lage")
            logger.debug(f"Parque Lage parsed - {len(eventos_parque_lage)} eventos")

            eventos_ccjf = safe_parse_venue(result_ccjf, "CCJF - Centro Cultural Justi√ßa Federal")
            logger.debug(f"CCJF parsed - {len(eventos_ccjf)} eventos")

            eventos_mam_cinema = safe_parse_venue(result_mam_cinema, "MAM Cinema")
            logger.debug(f"MAM Cinema parsed - {len(eventos_mam_cinema)} eventos")

            eventos_theatro_net = safe_parse_venue(result_theatro_net, "Theatro Net Rio")
            logger.debug(f"Theatro Net Rio parsed - {len(eventos_theatro_net)} eventos")

            eventos_ccbb_teatro_cinema = safe_parse_venue(result_ccbb_teatro_cinema, "CCBB Teatro e Cinema")
            logger.debug(f"CCBB Teatro e Cinema parsed - {len(eventos_ccbb_teatro_cinema)} eventos")

            eventos_istituto_italiano = safe_parse_venue(result_istituto_italiano, "Istituto Italiano di Cultura")
            logger.debug(f"Istituto Italiano parsed - {len(eventos_istituto_italiano)} eventos")

            eventos_maze_jazz = safe_parse_venue(result_maze_jazz, "Maze Jazz Club")
            logger.debug(f"Maze Jazz Club parsed - {len(eventos_maze_jazz)} eventos")

            eventos_teatro_leblon = safe_parse_venue(result_teatro_leblon, "Teatro do Leblon")
            logger.debug(f"Teatro do Leblon parsed - {len(eventos_teatro_leblon)} eventos")

            eventos_clube_jazz_rival = safe_parse_venue(result_clube_jazz_rival, "Clube do Jazz / Teatro Rival")
            logger.debug(f"Clube do Jazz/Rival parsed - {len(eventos_clube_jazz_rival)} eventos")

            eventos_estacao_net = safe_parse_venue(result_estacao_net, "Esta√ß√£o Net (Ipanema e Botafogo)")
            logger.debug(f"Esta√ß√£o Net parsed - {len(eventos_estacao_net)} eventos")

            # Criar estrutura de eventos de venues
            eventos_locais_merged = {
                "Casa do Choro": eventos_casa_choro,
                "Sala Cec√≠lia Meireles": eventos_sala_cecilia,
                "Teatro Municipal do Rio de Janeiro": eventos_teatro_municipal,
                "Artemis - Torrefa√ß√£o Artesanal e Cafeteria": eventos_artemis,
                "CCBB Rio - Centro Cultural Banco do Brasil": eventos_ccbb,
                "Oi Futuro": eventos_oi_futuro,
                "IMS - Instituto Moreira Salles": eventos_ims,
                "Parque Lage": eventos_parque_lage,
                "CCJF - Centro Cultural Justi√ßa Federal": eventos_ccjf,
                "MAM Cinema": eventos_mam_cinema,
                "Theatro Net Rio": eventos_theatro_net,
                "CCBB Teatro e Cinema": eventos_ccbb_teatro_cinema,
                "Istituto Italiano di Cultura": eventos_istituto_italiano,
                "Maze Jazz Club": eventos_maze_jazz,
                "Teatro do Leblon": eventos_teatro_leblon,
                "Clube do Jazz / Teatro Rival": eventos_clube_jazz_rival,
                "Esta√ß√£o Net (Ipanema e Botafogo)": eventos_estacao_net,
            }

            total_venues_before = sum(len(v) for v in eventos_locais_merged.values())
            logger.info(
                f"‚úì Merge conclu√≠do: {len(todos_eventos_gerais)} eventos gerais, "
                f"{total_venues_before} eventos de venues"
            )

            # Normalizar nomes de venues (consolidar CCBB Teatro I/II/III, etc.)
            logger.info(f"üîó Normalizando nomes de venues...")
            eventos_locais_merged = self._normalize_venue_names(eventos_locais_merged)

            # Aplicar limita√ß√£o de eventos por venue
            logger.info(f"üìä Aplicando limita√ß√£o de {MAX_EVENTS_PER_VENUE} eventos por venue...")
            eventos_locais_merged = self._limit_events_per_venue(eventos_locais_merged)

            total_venues_after = sum(len(v) for v in eventos_locais_merged.values())
            if total_venues_after < total_venues_before:
                logger.info(
                    f"üìä Limita√ß√£o aplicada: {total_venues_before} eventos ‚Üí {total_venues_after} eventos "
                    f"({total_venues_before - total_venues_after} removidos)"
                )

            # Retornar no formato compat√≠vel com o resto do sistema
            try:
                json_geral = json.dumps(eventos_gerais_merged, ensure_ascii=False)
                json_especial = json.dumps(eventos_locais_merged, ensure_ascii=False)

                result = {
                    "perplexity_geral": json_geral,
                    "perplexity_especial": json_especial,
                    "search_timestamp": datetime.now().isoformat(),
                }
                return result
            except Exception as json_error:
                logger.error(f"‚ùå Erro na serializa√ß√£o JSON: {json_error}")
                import traceback
                traceback.print_exc()
                raise

        except Exception as e:
            logger.error(f"‚ùå ERRO CR√çTICO nas micro-searches: {type(e).__name__}: {e}")
            logger.error("üìç Local do erro:")
            import traceback
            import sys
            exc_type, exc_value, exc_traceback = sys.exc_info()

            # Logar o traceback completo
            logger.error("=== TRACEBACK COMPLETO ===")
            traceback.print_exc()
            logger.error("=========================")

            # Logar informa√ß√µes sobre onde o erro ocorreu
            if exc_traceback:
                frame = exc_traceback.tb_frame
                lineno = exc_traceback.tb_lineno
                filename = frame.f_code.co_filename
                logger.error(f"Arquivo: {filename}, Linha: {lineno}")
                logger.error(f"Fun√ß√£o: {frame.f_code.co_name}")

            # Retornar JSONs vazios como fallback (para n√£o quebrar o pipeline)
            logger.warning("‚ö†Ô∏è  Retornando JSONs vazios como fallback")
            return {
                "perplexity_geral": "{}",
                "perplexity_especial": "{}",
                "search_timestamp": datetime.now().isoformat(),
            }

    def _find_event_ticket_link_batch(self, events_batch: list[dict]) -> dict[str, str]:
        """Busca links de m√∫ltiplos eventos em uma √∫nica chamada (batch)."""
        if not events_batch:
            return {}

        # Construir prompt com lista de eventos
        eventos_texto = []
        for i, event in enumerate(events_batch, 1):
            titulo = event.get("titulo", "")
            data = event.get("data", "")
            local = event.get("local", "")
            eventos_texto.append(f"{i}. {titulo} | Data: {data} | Local: {local}")

        # Usar PromptBuilder para construir prompt estruturado
        prompt = (
            PromptBuilder()
            .add_header(
                "MISS√ÉO CR√çTICA",
                f"Encontrar links ESPEC√çFICOS de venda/informa√ß√µes para estes {len(events_batch)} eventos no Rio de Janeiro."
            )
            .add_section("EVENTOS", "\n".join(eventos_texto))
            .add_raw("\nESTRAT√âGIA DE BUSCA OBRIGAT√ìRIA (siga esta ordem):\n\nPara CADA evento:")
            .add_numbered_list(
                "",
                [
                    """**PRIORIDADE M√ÅXIMA - Site Oficial do Venue**:
   - Blue Note Rio ‚Üí acesse bluenoterio.com e busque na agenda/programa√ß√£o
   - Teatro Municipal ‚Üí acesse theatromunicipal.rj.gov.br
   - Sala Cec√≠lia Meirelles ‚Üí acesse salaceliciameireles.com.br
   - Casa do Choro ‚Üí acesse casadochoro.com.br/agenda
   - Outros venues ‚Üí busque "[nome venue] agenda programa√ß√£o\"""",
                    """**Plataformas de Ingressos** (use termos EXATOS):
   - Sympla: busque "site:sympla.com.br [titulo evento completo] rio"
   - Ingresso.com: busque "site:ingresso.com [titulo evento completo]"
   - Eventbrite: busque "site:eventbrite.com.br [titulo evento completo]"
   - Bilheteria Digital, Ticket360, Uhuu""",
                    """**Redes Sociais/Instagram** (√∫ltimo recurso):
   - Busque Instagram oficial do venue com link na bio ou stories
   - Posts recentes sobre o evento espec√≠fico"""
                ],
                emoji_prefix=True
            )
            .add_criteria({
                "ACEITE APENAS": [
                    "URLs que levam DIRETAMENTE √† p√°gina do evento espec√≠fico",
                    "URLs com ID √∫nico, slug do evento, ou data na URL",
                    """Exemplos v√°lidos:
     * sympla.com.br/evento/nome-evento-123456
     * bluenoterio.com/shows/artista-data-20250115
     * eventbrite.com.br/e/titulo-evento-tickets-789012"""
                ],
                "REJEITE ABSOLUTAMENTE": [
                    "Homepages: bluenoterio.com, casadochoro.com.br",
                    "P√°ginas de listagem: /agenda, /shows, /eventos, /programacao",
                    "URLs gen√©ricas sem identificador do evento",
                    "Links de redes sociais (exceto se for o √öNICO link dispon√≠vel)"
                ]
            }, title="CRIT√âRIOS DE ACEITA√á√ÉO (seja RIGOROSO)")
            .add_numbered_list(
                "VALIDA√á√ÉO FINAL:\nAntes de retornar cada link",
                [
                    "Confirme que a URL cont√©m elemento √∫nico (ID, nome, data)",
                    "Verifique que n√£o √© p√°gina gen√©rica",
                    "Se tiver d√∫vida, retorne null"
                ]
            )
            .add_json_example(
                {
                    "1": "https://url-especifica-evento-1.com/... ou null",
                    "2": "https://url-especifica-evento-2.com/... ou null"
                },
                "FORMATO JSON (sem coment√°rios)"
            )
            .add_raw("‚ö†Ô∏è IMPORTANTE: Prefira retornar null do que um link gen√©rico. Links ruins ser√£o rejeitados na valida√ß√£o.")
            .build()
        )

        try:
            response = self.search_agent.run(prompt)
            content = response.content.strip()

            # Limpar markdown
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                content = content.split("```")[1].split("```")[0].strip()

            # Parse JSON
            links_map = json.loads(content)

            # Converter chaves para int se necess√°rio e validar formato
            result = {}
            for key, value in links_map.items():
                # Validar que o link n√£o √© gen√©rico
                if value and value != "null" and isinstance(value, str):
                    # Checar se n√£o √© link gen√©rico b√°sico
                    generic_endings = ['/shows/', '/eventos/', '/agenda/', '/programacao/', '/calendar/']
                    is_generic = any(value.rstrip('/').endswith(ending.rstrip('/')) for ending in generic_endings)

                    # Tamb√©m verificar se √© apenas homepage (sem path espec√≠fico)
                    from urllib.parse import urlparse
                    parsed = urlparse(value)
                    path = parsed.path.rstrip('/')

                    if is_generic or not path or path == '/':
                        logger.warning(f"   ‚ö†Ô∏è Link gen√©rico rejeitado: {value}")
                        result[str(key)] = None
                    else:
                        result[str(key)] = value
                else:
                    result[str(key)] = None

            return result

        except Exception as e:
            logger.error(f"Erro na busca batch de links: {e}")
            return {}

    def _search_missing_links(self, events: list[dict]) -> list[dict]:
        """Busca links para eventos que n√£o t√™m link, processando em batches."""
        # Identificar eventos sem link
        events_without_links = []
        events_indices = []

        for i, event in enumerate(events):
            if not event.get("link_ingresso"):
                events_without_links.append(event)
                events_indices.append(i)

        if not events_without_links:
            logger.info("Todos os eventos j√° possuem links")
            return events

        logger.info(f"üîó Buscando links para {len(events_without_links)} eventos sem link...")

        # Processar em batches de 5
        batch_size = 5
        total_found = 0

        for batch_start in range(0, len(events_without_links), batch_size):
            batch_end = min(batch_start + batch_size, len(events_without_links))
            batch = events_without_links[batch_start:batch_end]

            logger.info(f"   Processando batch {batch_start//batch_size + 1} ({len(batch)} eventos)...")

            # Buscar links para este batch
            links_map = self._find_event_ticket_link_batch(batch)

            # Atribuir links encontrados
            for local_idx, event in enumerate(batch):
                batch_key = str(local_idx + 1)
                if batch_key in links_map and links_map[batch_key]:
                    event["link_ingresso"] = links_map[batch_key]
                    event["link_source"] = "busca_complementar_batch"
                    total_found += 1
                    logger.info(f"   ‚úì Link encontrado para: {event.get('titulo')}")

        logger.info(f"‚úì Busca complementar conclu√≠da: {total_found}/{len(events_without_links)} links encontrados")
        return events

    def _filter_excluded_events(self, events: list[dict], category_name: str = "") -> list[dict]:
        """Filtra eventos que cont√™m palavras de exclus√£o no t√≠tulo ou descri√ß√£o.

        Args:
            events: Lista de eventos para filtrar
            category_name: Nome da categoria/venue (para logging)

        Returns:
            Lista de eventos filtrados (sem eventos que cont√™m keywords de exclus√£o)
        """
        from config import EVENT_CATEGORIES, GLOBAL_EXCLUDE_KEYWORDS

        # Iniciar com exclus√µes GLOBAIS (infantil, LGBTQ+, etc) - aplicadas a TODOS os eventos
        exclude_keywords = list(GLOBAL_EXCLUDE_KEYWORDS)

        # Adicionar exclus√µes espec√≠ficas de outdoor (shows mainstream) se aplic√°vel
        outdoor_exclude = EVENT_CATEGORIES.get("outdoor_parques", {}).get("exclude", [])
        if outdoor_exclude:
            exclude_keywords.extend(outdoor_exclude)

        if not exclude_keywords:
            return events

        filtered = []
        removed_count = 0

        for event in events:
            titulo = event.get("titulo", "").lower()
            descricao_raw = event.get("descricao", "") or ""  # Handle None values
            descricao = descricao_raw.lower()
            combined_text = f"{titulo} {descricao}"

            # Verificar se cont√©m alguma palavra de exclus√£o
            matched_keyword = None
            for keyword in exclude_keywords:
                if keyword.lower() in combined_text:
                    matched_keyword = keyword
                    break

            if matched_keyword:
                removed_count += 1
                logger.info(f"   ‚ùå Evento filtrado ({category_name}): '{event.get('titulo')}' [match: '{matched_keyword}']")
            else:
                filtered.append(event)

        if removed_count > 0:
            logger.info(f"‚úì Filtro de exclus√£o aplicado em {category_name}: {removed_count} eventos removidos, {len(filtered)} mantidos")

        return filtered

    def process_with_llm(self, raw_events: dict[str, Any]) -> str:
        """Combina e limpa resultados das duas buscas Perplexity."""
        logger.info("Combinando dados das 2 buscas Perplexity...")

        # Extrair dados das duas buscas
        data_geral = raw_events.get("perplexity_geral", "{}")
        data_especial = raw_events.get("perplexity_especial", "{}")

        # Limpar markdown code blocks e coment√°rios
        def clean_json(data):
            # Remover markdown code blocks
            if "```json" in data:
                data = data.split("```json")[1].split("```")[0].strip()
            elif "```" in data:
                data = data.split("```")[1].split("```")[0].strip()

            # Remover coment√°rios JavaScript (// coment√°rios) linha por linha
            lines = data.split("\n")
            cleaned_lines = []
            for line in lines:
                # Se a linha cont√©m //, remover tudo a partir da√≠ (exceto se estiver dentro de string)
                if "//" in line:
                    # Verificar se est√° dentro de string
                    in_string = False
                    quote_char = None
                    result = []
                    i = 0
                    while i < len(line):
                        char = line[i]
                        if char in ['"', "'"]:
                            if not in_string:
                                in_string = True
                                quote_char = char
                            elif char == quote_char and (i == 0 or line[i - 1] != "\\"):
                                in_string = False
                                quote_char = None
                            result.append(char)
                        elif char == "/" and i + 1 < len(line) and line[i + 1] == "/" and not in_string:
                            # Coment√°rio encontrado fora de string, parar aqui
                            break
                        else:
                            result.append(char)
                        i += 1
                    line = "".join(result).rstrip()
                cleaned_lines.append(line)

            # Remover linhas vazias
            cleaned_lines = [line for line in cleaned_lines if line.strip()]

            return "\n".join(cleaned_lines)

        data_geral_clean = clean_json(data_geral)
        data_especial_clean = clean_json(data_especial)

        # Combinar em um √∫nico JSON
        combined = f'{{"eventos_gerais": {data_geral_clean}, "eventos_locais_especiais": {data_especial_clean}}}'

        logger.info("Dados combinados das 2 buscas")

        # Parsear para aplicar busca complementar de links
        try:
            combined_data = json.loads(combined)

            # Extrair todos os eventos para busca complementar
            all_events = []

            # Eventos gerais
            if "eventos_gerais" in combined_data and "eventos" in combined_data["eventos_gerais"]:
                all_events.extend(combined_data["eventos_gerais"]["eventos"])

            # Eventos de locais especiais
            if "eventos_locais_especiais" in combined_data:
                for local_name, local_events in combined_data["eventos_locais_especiais"].items():
                    if isinstance(local_events, list):
                        all_events.extend([e for e in local_events if isinstance(e, dict)])

            # Aplicar busca complementar de links
            if all_events:
                self._search_missing_links(all_events)

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # APLICAR FILTRO DE EXCLUS√ÉO (remover samba, ax√©, mainstream)
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            logger.info("üîç Aplicando filtro de exclus√£o...")

            # Filtrar eventos gerais (categorias: Jazz, Teatro-Com√©dia, Outdoor-FimDeSemana)
            if "eventos_gerais" in combined_data and "eventos" in combined_data["eventos_gerais"]:
                original_count = len(combined_data["eventos_gerais"]["eventos"])
                combined_data["eventos_gerais"]["eventos"] = self._filter_excluded_events(
                    combined_data["eventos_gerais"]["eventos"],
                    "eventos_gerais"
                )
                final_count = len(combined_data["eventos_gerais"]["eventos"])
                logger.info(f"üìä Eventos gerais: {original_count} ‚Üí {final_count} (removidos: {original_count - final_count})")

            # Filtrar eventos de locais especiais (Casa do Choro, Sala Cec√≠lia, Teatro Municipal, Artemis)
            if "eventos_locais_especiais" in combined_data:
                for local_name, local_events in combined_data["eventos_locais_especiais"].items():
                    if isinstance(local_events, list) and local_events:
                        original_count = len(local_events)
                        combined_data["eventos_locais_especiais"][local_name] = self._filter_excluded_events(
                            local_events,
                            local_name
                        )
                        final_count = len(combined_data["eventos_locais_especiais"][local_name])
                        if original_count != final_count:
                            logger.info(f"üìä {local_name}: {original_count} ‚Üí {final_count} (removidos: {original_count - final_count})")

            logger.info("‚úÖ Filtro de exclus√£o aplicado com sucesso")

            # Retornar JSON atualizado
            return json.dumps(combined_data, ensure_ascii=False, indent=2)

        except json.JSONDecodeError as e:
            logger.error(f"Erro ao parsear JSON combinado: {e}")
            return combined
