"""Agente de busca de eventos."""

import asyncio
import json
import logging
from datetime import datetime
from typing import Any

from pydantic import ValidationError

from agents.base_agent import BaseAgent
from config import SEARCH_CONFIG, MAX_EVENTS_PER_VENUE
from models.event_models import ResultadoBuscaCategoria
from utils.deduplicator import deduplicate_events
from utils.prompt_templates import PromptBuilder
from utils.prompt_loader import get_prompt_loader

logger = logging.getLogger(__name__)


class SearchAgent(BaseAgent):
    """Agente responsÃ¡vel por buscar eventos em mÃºltiplas fontes."""

    def __init__(self):
        super().__init__(
            agent_name="SearchAgent",
            log_emoji="ğŸ”",
            model_type="search",  # perplexity/sonar-pro
            description="Agente com busca web em tempo real para encontrar eventos culturais no Rio de Janeiro",
            instructions=[
                f"VocÃª tem acesso Ã  busca web em tempo real. Use para encontrar eventos no Rio de Janeiro "
                f"entre {SEARCH_CONFIG['start_date'].strftime('%d/%m/%Y')} "
                f"e {SEARCH_CONFIG['end_date'].strftime('%d/%m/%Y')}",
                "Busque nas seguintes categorias:",
                "1. Shows de jazz no Rio (prÃ³ximas 3 semanas)",
                "2. Teatro comÃ©dia/stand-up no Rio (EXCETO eventos infantis)",
                "3. Eventos na Casa do Choro, Sala CecÃ­lia Meireles e Teatro Municipal",
                "4. Eventos ao ar livre em fim de semana no Rio",
                "Para cada evento, extrair: tÃ­tulo, data completa, horÃ¡rio, local, valor/preÃ§o, link para compra de ingressos",
                "Buscar em sites como: Sympla, Eventbrite, Fever, TimeOut Rio, sites oficiais dos locais",
                "Retorne no formato JSON estruturado",
            ],
            markdown=True,
        )

        # Renomear agent para compatibilidade
        self.search_agent = self.agent

    def _initialize_dependencies(self, **kwargs):
        """Inicializa prompt loader."""
        self.prompt_loader = get_prompt_loader()
        self.log_info(
            f"ğŸ“‹ Prompts carregados: "
            f"{len(self.prompt_loader.get_all_categorias())} categorias, "
            f"{len(self.prompt_loader.get_all_venues())} venues"
        )

    def _limit_events_per_venue(self, eventos_por_venue: dict[str, list[dict]]) -> dict[str, list[dict]]:
        """
        Limita eventos por venue ao mÃ¡ximo definido em MAX_EVENTS_PER_VENUE.

        CritÃ©rios de priorizaÃ§Ã£o (em ordem):
        1. Eventos com link vÃ¡lido (prioridade alta)
        2. Diversidade de datas (evita concentraÃ§Ã£o no mesmo dia)
        3. Completude da descriÃ§Ã£o (mais informaÃ§Ã£o = melhor)
        4. Ordem cronolÃ³gica (mais prÃ³ximos primeiro)
        """
        limited_events = {}

        for venue_name, eventos in eventos_por_venue.items():
            if len(eventos) <= MAX_EVENTS_PER_VENUE:
                limited_events[venue_name] = eventos
                continue

            # Calcular score para cada evento
            scored_events = []
            for evento in eventos:
                score = 0

                # 1. Link vÃ¡lido = +100 pontos
                if evento.get("link_ingresso") and evento["link_ingresso"].lower() not in ("null", "none", ""):
                    score += 100

                # 2. DescriÃ§Ã£o completa = +50 pontos (se > 50 palavras)
                descricao = evento.get("descricao", "") or ""
                if len(descricao.split()) > 50:
                    score += 50
                elif len(descricao.split()) > 20:
                    score += 25

                # 3. Data mais prÃ³xima = +1 a +30 pontos (inverso da posiÃ§Ã£o)
                try:
                    data_str = evento.get("data", "")
                    if data_str:
                        # Parsear DD/MM/YYYY
                        data_evento = datetime.strptime(data_str, "%d/%m/%Y")
                        # Quanto mais prÃ³ximo, maior o score (max 30 pontos)
                        days_diff = (data_evento - datetime.now()).days
                        if days_diff >= 0:
                            # Normalizar: 0-21 dias â†’ 30-10 pontos
                            score += max(10, 30 - days_diff)
                except:
                    score += 15  # score neutro se data invÃ¡lida

                scored_events.append((score, evento))

            # Ordenar por score (maior primeiro)
            scored_events.sort(key=lambda x: x[0], reverse=True)

            # Selecionar top MAX_EVENTS_PER_VENUE
            selected = [evento for _, evento in scored_events[:MAX_EVENTS_PER_VENUE]]
            limited_events[venue_name] = selected

            # Log da reduÃ§Ã£o
            if len(eventos) > MAX_EVENTS_PER_VENUE:
                logger.info(
                    f"ğŸ“Š Venue '{venue_name}': {len(eventos)} eventos â†’ "
                    f"{len(selected)} selecionados (limite: {MAX_EVENTS_PER_VENUE})"
                )

        return limited_events

    def _normalize_venue_names(self, eventos_por_venue: dict[str, list[dict]]) -> dict[str, list[dict]]:
        """
        Consolida sub-venues em venues principais usando VENUE_ALIASES.

        Exemplo: "CCBB Teatro III" â†’ "CCBB Rio - Centro Cultural Banco do Brasil"
        """
        from config import VENUE_ALIASES

        normalized = {}
        consolidation_log = []

        for venue_name, eventos in eventos_por_venue.items():
            # Obter nome canÃ´nico do venue
            canonical_name = VENUE_ALIASES.get(venue_name, venue_name)

            # Log de consolidaÃ§Ã£o se houve mudanÃ§a
            if canonical_name != venue_name and len(eventos) > 0:
                consolidation_log.append(f"{venue_name} â†’ {canonical_name} ({len(eventos)} eventos)")

            # Merge eventos no venue canÃ´nico
            if canonical_name not in normalized:
                normalized[canonical_name] = []
            normalized[canonical_name].extend(eventos)

        # Log consolidaÃ§Ãµes realizadas
        if consolidation_log:
            logger.info(f"ğŸ”— ConsolidaÃ§Ã£o de venues:")
            for log_msg in consolidation_log:
                logger.info(f"   - {log_msg}")

        return normalized

    async def _run_micro_search(self, prompt: str, search_name: str) -> str:
        """Executa uma micro-search focada de forma assÃ­ncrona."""
        logger.info(f"   ğŸ” Iniciando busca: {search_name}")

        def sync_search():
            try:
                response = self.search_agent.run(prompt)
                return response.content
            except Exception as e:
                logger.error(f"Erro na busca {search_name}: {e}")
                return "{}"

        result = await asyncio.to_thread(sync_search)

        # Log resposta do Perplexity para diagnÃ³stico (primeiros 500 chars)
        if result and result.strip():
            preview = result[:500].replace('\n', ' ')
            logger.debug(f"   ğŸ“„ Resposta Perplexity [{search_name}]: {preview}...")

        logger.info(f"   âœ“ Busca concluÃ­da: {search_name}")
        return result

    def _build_focused_prompt(
        self,
        categoria: str,
        tipo_busca: str,  # "categoria" ou "venue"
        descricao: str,
        tipos_evento: list[str],
        palavras_chave: list[str],
        venues_sugeridos: list[str],
        instrucoes_especiais: str = "",
        start_date_str: str = "",
        end_date_str: str = "",
        month_year_str: str = "",
        month_str: str = "",
    ) -> str:
        """ConstrÃ³i prompt focado para uma Ãºnica categoria ou venue (DRY)."""

        # Template comum para todos os prompts
        common_header = f"""Execute uma busca FOCADA e DETALHADA exclusivamente para: {categoria}

PERÃODO: {start_date_str} a {end_date_str}

ğŸ¯ FOCO EXCLUSIVO: {descricao}

ESTRATÃ‰GIA DE BUSCA:
"""

        # SeÃ§Ã£o de tipos de evento
        tipos_section = "TIPOS DE EVENTO:\n"
        for tipo in tipos_evento:
            tipos_section += f"- {tipo}\n"

        # SeÃ§Ã£o de palavras-chave
        keywords_section = "\nPALAVRAS-CHAVE PARA BUSCA:\n"
        for keyword in palavras_chave:
            keywords_section += f'- "{keyword}"\n'

        # SeÃ§Ã£o de venues
        venues_section = "\nVENUES/LOCAIS PRIORITÃRIOS:\n"
        for venue in venues_sugeridos:
            venues_section += f"- {venue}\n"

        # Fontes (comum para todos)
        sources_section = """
FONTES PARA BUSCAR:
- Sympla (sympla.com.br), Eventbrite (eventbrite.com.br), Fever (fever.com.br)
- Portais culturais: TimeOut Rio, Veja Rio, O Globo Cultura
- Sites oficiais dos venues e suas redes sociais (Instagram/Facebook)
- Bilheterias online oficiais dos locais
"""

        # Campos obrigatÃ³rios (comum para todos)
        required_fields = """
INFORMAÃ‡Ã•ES OBRIGATÃ“RIAS PARA CADA EVENTO:
- Nome completo do evento
- Data exata (formato DD/MM/YYYY)
- âš ï¸ HorÃ¡rio de inÃ­cio (HH:MM) - CRÃTICO: SEMPRE inclua o horÃ¡rio preciso
- Nome completo do local/venue + endereÃ§o
- PreÃ§o (incluir meia-entrada se disponÃ­vel)
- Link para compra de ingressos (se disponÃ­vel)
- DescriÃ§Ã£o detalhada: artistas, duraÃ§Ã£o, pÃºblico-alvo

ATENÃ‡ÃƒO ESPECIAL AO HORÃRIO:
- O horÃ¡rio Ã© OBRIGATÃ“RIO (nÃ£o opcional)
- Formato: "19:00", "20:30", "21:00" (HH:MM)
- Se o site nÃ£o mostrar horÃ¡rio, busque em Instagram, Facebook, Sympla, Eventbrite
- NUNCA deixe horÃ¡rio em branco
"""

        # Formato de retorno (diferente para categoria vs venue)
        if tipo_busca == "categoria":
            return_format = f"""
FORMATO DE RETORNO:
{{
  "eventos": [
    {{
      "categoria": "{categoria}",
      "titulo": "Nome do evento",
      "data": "DD/MM/YYYY",
      "horario": "HH:MM",
      "local": "Nome completo + EndereÃ§o",
      "preco": "Valor completo",
      "link_ingresso": "URL especÃ­fica ou null",
      "descricao": "DescriÃ§Ã£o detalhada"
    }}
  ]
}}

IMPORTANTE:
- Busque o MÃXIMO de eventos possÃ­vel (objetivo: pelo menos 3 eventos)
- INCLUA TODOS os eventos que encontrar com data, horÃ¡rio, local e descriÃ§Ã£o

âš ï¸ REGRAS CRÃTICAS PARA LINKS (leia com atenÃ§Ã£o - links invÃ¡lidos serÃ£o rejeitados):

1. NÃƒO RETORNE HOMEPAGES/SITES INSTITUCIONAIS:
   âŒ NUNCA retornar sites de ARTISTAS (ex: raphaelghanem.com.br, fabriciolins.com.br)
   âŒ NUNCA retornar homepages de VENUES (ex: casadochoro.com.br, teatroopuscitta.com.br)
   âŒ NUNCA retornar homepages de PLATAFORMAS (ex: sympla.com.br, ingresso.com)
   âŒ NUNCA retornar AGREGADORES genÃ©ricos (ex: shazam.com/events, concerts50.com, songkick.com)
   âŒ NUNCA retornar pÃ¡ginas de PROGRAMAÃ‡ÃƒO GERAL (ex: /programacao, /agenda, /calendario)

2. O link DEVE conter IDENTIFICADOR ÃšNICO do evento (um destes formatos):
   - ID numÃ©rico: /evento/nome-do-evento/123456
   - Slug com data: /evento-nome-18-11-2025
   - Hash alfanumÃ©rico: /shows/nome__abc123de/
   - ParÃ¢metro Ãºnico: ?event_id=789 ou ?eve_cod=15246

3. PLATAFORMAS DE BUSCA (nesta ordem de prioridade):
   ğŸ¥‡ PRIORITÃRIAS (sempre buscar primeiro):
   a) Sympla: sympla.com.br/evento/[nome]/[ID-numerico]
   b) Eventbrite: eventbrite.com.br/e/[nome]-tickets-[ID]
   c) Ticketmaster: ticketmaster.com.br/event/[ID]
   d) Fever: feverup.com/rio-de-janeiro/events/[nome-evento]

   ğŸ¥ˆ SECUNDÃRIAS (se prioritÃ¡rias nÃ£o tiverem):
   e) Ingresso.com: ingresso.com/evento/[nome]/[ID]
   f) Bileto: bileto.sympla.com.br/event/[ID]

   ğŸ¥‰ VENUES ESPECÃFICOS (apenas com pÃ¡gina do evento):
   g) Blue Note: bluenoterio.com.br/shows/[nome-show]__[hash]/
   h) Sites oficiais com link ESPECÃFICO do evento (NÃƒO homepage)

âœ… EXEMPLOS DE LINKS VÃLIDOS:
   âœ… https://www.sympla.com.br/evento/raphael-ghanem-stand-up/2345678
   âœ… https://www.eventbrite.com.br/e/quarteto-de-cordas-da-osb-tickets-987654321
   âœ… https://bluenoterio.com.br/shows/irma-you-and-my-guitar__22hz624n/
   âœ… https://www.ingresso.com/evento/caio-martins-segredo-revelado/15246

âŒ EXEMPLOS DE LINKS INVÃLIDOS (NUNCA RETORNAR):
   HOMEPAGES E SITES INSTITUCIONAIS:
   âŒ https://raphaelghanem.com.br (site oficial do artista)
   âŒ https://casadochoro.com.br (homepage do venue)
   âŒ https://teatroopuscitta.com.br (homepage do teatro)
   âŒ https://www.sympla.com.br (homepage da plataforma)

   AGREGADORES GENÃ‰RICOS (nÃ£o vendem ingressos):
   âŒ https://shazam.com/events/rio-de-janeiro (apenas lista eventos)
   âŒ https://concerts50.com/brazil/rio-de-janeiro (agregador de terceiros)

   PÃGINAS DE CATEGORIA/BUSCA/LISTAGEM:
   âŒ https://www.ingresso.com/espetaculos/categorias/stand-up (categoria genÃ©rica)
   âŒ https://www.sympla.com.br/eventos/rio-de-janeiro (listagem por cidade)
   âŒ https://eventbrite.com.br/d/brazil--rio-de-janeiro/events/ (listagem)
   âŒ https://bluenoterio.com.br/shows (listagem de todos os shows - falta ID especÃ­fico)

   PROGRAMAÃ‡ÃƒO GERAL DE VENUES:
   âŒ https://salaceliciameireles.rj.gov.br/programacao (calendÃ¡rio mensal)
   âŒ https://casadochoro.com.br/programacao (agenda geral)

ğŸ“‹ CHECKLIST ANTES DE RETORNAR UM LINK:
   âœ… O link contÃ©m ID/identificador Ãºnico? (numÃ©rico, slug, hash, ou parÃ¢metro)
   âœ… O link Ã© de uma PLATAFORMA de venda (Sympla, Eventbrite, etc) OU pÃ¡gina especÃ­fica do venue?
   âœ… O link aponta para UMA pÃ¡gina especÃ­fica de evento (nÃ£o listagem/categoria)?
   âœ… O link NÃƒO Ã© homepage do artista/venue/plataforma?
   âœ… O link NÃƒO Ã© de agregador genÃ©rico (Shazam, Concerts50, etc)?

   SE TODAS AS RESPOSTAS FOREM âœ… â†’ retornar link
   SE QUALQUER RESPOSTA FOR âŒ â†’ retornar null

4. SE NÃƒO ENCONTRAR link especÃ­fico:
   - Busque em TODAS as plataformas prioritÃ¡rias (Sympla, Eventbrite, Ticketmaster, Fever)
   - Busque em plataformas secundÃ¡rias (Ingresso.com, Bileto)
   - APENAS APÃ“S TENTAR TODAS AS FONTES: retorne null
   - NÃƒO retorne links genÃ©ricos "por garantia" (null Ã© MELHOR que link invÃ¡lido)
"""
        else:  # venue
            return_format = f"""
ENCODING E CARACTERES ESPECIAIS:
- Usar UTF-8 encoding para TODOS os campos
- Caracteres acentuados sÃ£o PERMITIDOS e DEVEM ser escritos normalmente (ex: "CecÃ­lia", "mÃºsica", "sÃ¡bado")
- NÃƒO usar escapes unicode (ex: \\u00ed) - escrever os caracteres acentuados diretamente
- A chave do JSON DEVE ser EXATAMENTE: "{categoria}" (preservar acentuaÃ§Ã£o se houver)

FORMATO DE RETORNO (use exatamente estes nomes de campos):
{{
  "{categoria}": [
    {{
      "titulo": "Nome do evento",
      "data": "DD/MM/YYYY",
      "horario": "HH:MM",
      "local": "{categoria} - EndereÃ§o completo",
      "preco": "Valor completo",
      "link_ingresso": "URL especÃ­fica ou null",
      "descricao": "DescriÃ§Ã£o detalhada"
    }}
  ]
}}

IMPORTANTE - NOMES DE CAMPOS:
- Use "horario" (nÃ£o "hora")
- Use "preco" (nÃ£o "preÃ§o")
- Use "link_ingresso" (nÃ£o "link")
- Use "descricao" (nÃ£o "descriÃ§Ã£o")

REGRAS CRÃTICAS PARA JSON:
1. Comece DIRETAMENTE com {{ (sem markdown, sem textos, sem cabeÃ§alhos antes)
2. Se usar markdown, use APENAS ```json no inÃ­cio e ``` no final
3. Feche COMPLETAMENTE o JSON antes de qualquer texto explicativo
4. NÃƒO adicione nada DEPOIS do Ãºltimo }}
5. Caracteres especiais devem ser escritos normalmente (ex: "Ã ", "Ã£", "Ã§", "Ã©", "Ã­", "Ã³", "Ã´", "Ãµ", "Ã¼")

OBJETIVO:
- Busque o MÃXIMO de eventos possÃ­vel (objetivo: pelo menos 1 evento)
- INCLUA TODOS os eventos que encontrar com data, horÃ¡rio, local e descriÃ§Ã£o

âš ï¸ REGRAS CRÃTICAS PARA LINKS (leia com atenÃ§Ã£o - links invÃ¡lidos serÃ£o rejeitados):

1. NÃƒO RETORNE HOMEPAGES/SITES INSTITUCIONAIS:
   âŒ NUNCA retornar sites de ARTISTAS (ex: raphaelghanem.com.br, fabriciolins.com.br)
   âŒ NUNCA retornar homepages de VENUES (ex: casadochoro.com.br, teatroopuscitta.com.br)
   âŒ NUNCA retornar homepages de PLATAFORMAS (ex: sympla.com.br, ingresso.com)
   âŒ NUNCA retornar AGREGADORES genÃ©ricos (ex: shazam.com/events, concerts50.com, songkick.com)
   âŒ NUNCA retornar pÃ¡ginas de PROGRAMAÃ‡ÃƒO GERAL (ex: /programacao, /agenda, /calendario)

2. O link DEVE conter IDENTIFICADOR ÃšNICO do evento (um destes formatos):
   - ID numÃ©rico: /evento/nome-do-evento/123456
   - Slug com data: /evento-nome-18-11-2025
   - Hash alfanumÃ©rico: /shows/nome__abc123de/
   - ParÃ¢metro Ãºnico: ?event_id=789 ou ?eve_cod=15246

3. PLATAFORMAS DE BUSCA (nesta ordem de prioridade):
   ğŸ¥‡ PRIORITÃRIAS (sempre buscar primeiro):
   a) Sympla: sympla.com.br/evento/[nome]/[ID-numerico]
   b) Eventbrite: eventbrite.com.br/e/[nome]-tickets-[ID]
   c) Ticketmaster: ticketmaster.com.br/event/[ID]
   d) Fever: feverup.com/rio-de-janeiro/events/[nome-evento]

   ğŸ¥ˆ SECUNDÃRIAS (se prioritÃ¡rias nÃ£o tiverem):
   e) Ingresso.com: ingresso.com/evento/[nome]/[ID]
   f) Bileto: bileto.sympla.com.br/event/[ID]

   ğŸ¥‰ VENUES ESPECÃFICOS (apenas com pÃ¡gina do evento):
   g) Blue Note: bluenoterio.com.br/shows/[nome-show]__[hash]/
   h) Sites oficiais com link ESPECÃFICO do evento (NÃƒO homepage)

âœ… EXEMPLOS DE LINKS VÃLIDOS:
   âœ… https://www.sympla.com.br/evento/raphael-ghanem-stand-up/2345678
   âœ… https://www.eventbrite.com.br/e/quarteto-de-cordas-da-osb-tickets-987654321
   âœ… https://bluenoterio.com.br/shows/irma-you-and-my-guitar__22hz624n/
   âœ… https://www.ingresso.com/evento/caio-martins-segredo-revelado/15246

âŒ EXEMPLOS DE LINKS INVÃLIDOS (NUNCA RETORNAR):
   HOMEPAGES E SITES INSTITUCIONAIS:
   âŒ https://raphaelghanem.com.br (site oficial do artista)
   âŒ https://casadochoro.com.br (homepage do venue)
   âŒ https://teatroopuscitta.com.br (homepage do teatro)
   âŒ https://www.sympla.com.br (homepage da plataforma)

   AGREGADORES GENÃ‰RICOS (nÃ£o vendem ingressos):
   âŒ https://shazam.com/events/rio-de-janeiro (apenas lista eventos)
   âŒ https://concerts50.com/brazil/rio-de-janeiro (agregador de terceiros)

   PÃGINAS DE CATEGORIA/BUSCA/LISTAGEM:
   âŒ https://www.ingresso.com/espetaculos/categorias/stand-up (categoria genÃ©rica)
   âŒ https://www.sympla.com.br/eventos/rio-de-janeiro (listagem por cidade)
   âŒ https://eventbrite.com.br/d/brazil--rio-de-janeiro/events/ (listagem)
   âŒ https://bluenoterio.com.br/shows (listagem de todos os shows - falta ID especÃ­fico)

   PROGRAMAÃ‡ÃƒO GERAL DE VENUES:
   âŒ https://salaceliciameireles.rj.gov.br/programacao (calendÃ¡rio mensal)
   âŒ https://casadochoro.com.br/programacao (agenda geral)

ğŸ“‹ CHECKLIST ANTES DE RETORNAR UM LINK:
   âœ… O link contÃ©m ID/identificador Ãºnico? (numÃ©rico, slug, hash, ou parÃ¢metro)
   âœ… O link Ã© de uma PLATAFORMA de venda (Sympla, Eventbrite, etc) OU pÃ¡gina especÃ­fica do venue?
   âœ… O link aponta para UMA pÃ¡gina especÃ­fica de evento (nÃ£o listagem/categoria)?
   âœ… O link NÃƒO Ã© homepage do artista/venue/plataforma?
   âœ… O link NÃƒO Ã© de agregador genÃ©rico (Shazam, Concerts50, etc)?

   SE TODAS AS RESPOSTAS FOREM âœ… â†’ retornar link
   SE QUALQUER RESPOSTA FOR âŒ â†’ retornar null

4. SE NÃƒO ENCONTRAR link especÃ­fico:
   - Busque em TODAS as plataformas prioritÃ¡rias (Sympla, Eventbrite, Ticketmaster, Fever)
   - Busque em plataformas secundÃ¡rias (Ingresso.com, Bileto)
   - APENAS APÃ“S TENTAR TODAS AS FONTES: retorne null
   - NÃƒO retorne links genÃ©ricos "por garantia" (null Ã© MELHOR que link invÃ¡lido)
"""

        # Montar prompt completo
        return (
            common_header
            + tipos_section
            + keywords_section
            + venues_section
            + sources_section
            + instrucoes_especiais
            + required_fields
            + return_format
        )

    def _get_saturdays_in_period(self, start_date, end_date) -> list[dict]:
        """
        Retorna lista de sÃ¡bados no perÃ­odo de busca.

        Args:
            start_date: Data inicial (datetime)
            end_date: Data final (datetime)

        Returns:
            Lista de dicts com info de cada sÃ¡bado: [{"date": datetime, "date_str": "15/11/2025"}, ...]
        """
        from datetime import timedelta

        saturdays = []
        current = start_date

        # Iterar dia por dia atÃ© end_date
        while current <= end_date:
            # weekday() retorna 5 para sÃ¡bado (0=segunda, 6=domingo)
            if current.weekday() == 5:
                saturdays.append({
                    "date": current,
                    "date_str": current.strftime("%d/%m/%Y")
                })
            current += timedelta(days=1)

        return saturdays

    def _build_saturday_outdoor_prompt(self, saturday_date_str: str, month_str: str) -> str:
        """
        ConstrÃ³i prompt ultra-focado para buscar eventos outdoor em UM sÃ¡bado especÃ­fico.

        Args:
            saturday_date_str: Data do sÃ¡bado no formato DD/MM/YYYY
            month_str: Nome do mÃªs em inglÃªs (ex: "november")

        Returns:
            Prompt completo formatado
        """
        return f"""
ğŸ¯ BUSCA ULTRA-FOCADA: Eventos Outdoor no Rio APENAS no dia {saturday_date_str} (SÃBADO)

OBJETIVO: Encontrar eventos culturais ao ar livre ESPECIFICAMENTE neste sÃ¡bado.

TIPOS DE EVENTOS:
- ğŸ¬ Cinema ao ar livre
- ğŸµ Concertos em parques
- ğŸ›ï¸ Feiras culturais nichadas
- ğŸŒ³ Eventos em parques/jardins

ESTRATÃ‰GIA DE BUSCA - FOCO EM EVENTOS RECORRENTES:

1. ğŸ” **Feiras Recorrentes aos SÃ¡bados**:
   - Feira da PraÃ§a XV (todos os sÃ¡bados): site:bafafa.com.br "feira praÃ§a xv" {saturday_date_str}
   - Feira Rio Antigo (1Âº sÃ¡bado): site:visit.rio "feira rio antigo" {month_str}
   - Feiras de artesanato em parques: site:timeout.com/rio-de-janeiro feira {month_str}

2. ğŸ” **Cinema ao Ar Livre**:
   - "cinema ao ar livre rio sÃ¡bado {saturday_date_str}"
   - Parque Lage, Jardim BotÃ¢nico, Aterro: site:parquelage.rj.gov.br cinema {month_str}

3. ğŸ” **Concertos em Parques**:
   - "concerto jardim botÃ¢nico {saturday_date_str}"
   - "mÃºsica ao ar livre rio {saturday_date_str}"

4. ğŸ” **Eventos em Locais EspecÃ­ficos**:
   - Jardim BotÃ¢nico: Instagram @jardimbotanicorj
   - Parque Lage: Instagram @parquelage
   - Quinta da Boa Vista: eventos culturais

FONTES OBRIGATÃ“RIAS:
- site:bafafa.com.br eventos rio {saturday_date_str}
- site:visit.rio agenda {saturday_date_str}
- site:timeout.com/rio-de-janeiro fim-de-semana

âš ï¸ EXCLUSÃ•ES:
- âŒ Samba, pagode, forrÃ³, axÃ©
- âŒ Eventos esportivos (corridas, maratonas)
- âŒ Mega shows em estÃ¡dios

INFORMAÃ‡Ã•ES OBRIGATÃ“RIAS:
- titulo: Nome do evento
- data: {saturday_date_str} (fixo - este sÃ¡bado)
- horario: HH:MM (obrigatÃ³rio)
- local: Nome + endereÃ§o completo
- preco: Valor ou "Gratuito"
- link_ingresso: URL especÃ­fica ou null
- descricao: Resumo do evento

FORMATO DE RETORNO:
{{
  "eventos": [
    {{
      "categoria": "Outdoor/Parques",
      "titulo": "Nome do evento",
      "data": "{saturday_date_str}",
      "horario": "HH:MM",
      "local": "Nome + EndereÃ§o",
      "preco": "Valor",
      "link_ingresso": "URL ou null",
      "descricao": "Resumo"
    }}
  ]
}}

IMPORTANTE:
- Retornar APENAS eventos confirmados para {saturday_date_str}
- Se nÃ£o encontrar eventos: retornar {{"eventos": []}}
- Priorizar eventos RECORRENTES (feiras fixas aos sÃ¡bados)
"""

    def _build_prompt_from_config(self, config: dict, context: dict) -> str:
        """
        ConstrÃ³i prompt a partir de configuraÃ§Ã£o YAML.

        Args:
            config: ConfiguraÃ§Ã£o carregada do YAML (categoria ou venue)
            context: Contexto com variÃ¡veis de data (start_date_str, end_date_str, etc)

        Returns:
            Prompt completo formatado
        """
        # Nomes dos campos variam se Ã© categoria ou venue
        # Para categoria: venues_sugeridos
        # Para venue: pode nÃ£o ter venues_sugeridos (usar lista vazia)

        venues_list = config.get("venues_sugeridos", config.get("fontes_prioritarias", []))

        return self._build_focused_prompt(
            categoria=config["nome"],
            tipo_busca=config["tipo_busca"],
            descricao=config["descricao"],
            tipos_evento=config["tipos_evento"],
            palavras_chave=config["palavras_chave"],
            venues_sugeridos=venues_list if isinstance(venues_list, list) else [],
            instrucoes_especiais=config.get("instrucoes_especiais", ""),
            start_date_str=context["start_date_str"],
            end_date_str=context["end_date_str"],
            month_year_str=context["month_year_str"],
            month_str=context["month_str"]
        )

    async def search_all_sources(self) -> dict[str, Any]:
        """Busca eventos usando Perplexity Sonar Pro com 6 micro-searches focadas."""
        logger.info(f"{self.log_prefix} Iniciando busca de eventos com Perplexity Sonar Pro...")

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # PRIORIDADE 1: SCRAPERS CUSTOMIZADOS (Blue Note + Sala CecÃ­lia Meireles)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        logger.info(f"{self.log_prefix} ğŸ« Buscando eventos via scrapers customizados...")
        from utils.eventim_scraper import EventimScraper

        # Blue Note
        blue_note_scraped = EventimScraper.scrape_blue_note_events()
        if blue_note_scraped:
            logger.info(f"âœ“ Encontrados {len(blue_note_scraped)} eventos Blue Note no Eventim")
        else:
            logger.warning("âš ï¸  Nenhum evento Blue Note encontrado no scraper")

        # Sala CecÃ­lia Meireles
        cecilia_meireles_scraped = EventimScraper.scrape_cecilia_meireles_events()
        if cecilia_meireles_scraped:
            logger.info(f"âœ“ Encontrados {len(cecilia_meireles_scraped)} eventos Sala CecÃ­lia Meireles")
        else:
            logger.warning("âš ï¸  Nenhum evento Sala CecÃ­lia Meireles encontrado no scraper")

        # CCBB Rio
        ccbb_scraped = EventimScraper.scrape_ccbb_events()
        if ccbb_scraped:
            logger.info(f"âœ“ Encontrados {len(ccbb_scraped)} eventos CCBB")
        else:
            logger.warning("âš ï¸  Nenhum evento CCBB encontrado no scraper")

        # Teatro Municipal - REMOVIDO
        # Site oficial nÃ£o tem estrutura adequada para scraping
        # Fever carrega eventos via JavaScript (nÃ£o scrapÃ¡vel)
        # Perplexity consegue encontrar os eventos via busca web
        teatro_municipal_scraped = []
        logger.info("âœ“ Teatro Municipal: delegado para Perplexity (Fever usa JS)")

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # CARREGAR PROMPTS DO YAML
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Construir contexto de datas para interpolaÃ§Ã£o
        context = self.prompt_loader.build_context(
            SEARCH_CONFIG['start_date'],
            SEARCH_CONFIG['end_date']
        )

        logger.info(f"{self.log_prefix} Criando prompts a partir do YAML...")


        # Carregar configuraÃ§Ãµes de categorias e construir prompts
        categorias_ids = ["jazz", "comedia", "musica_classica", "outdoor", "cinema", "feira_gastronomica", "feira_artesanato"]
        prompts_categorias = {}

        for cat_id in categorias_ids:
            config = self.prompt_loader.get_categoria(cat_id, context)
            prompts_categorias[cat_id] = self._build_prompt_from_config(config, context)

        # Carregar configuraÃ§Ãµes de venues e construir prompts
        venues_ids = [
            "casa_choro", "sala_cecilia", "teatro_municipal", "artemis", "ccbb",
            "oi_futuro", "ims", "parque_lage", "ccjf", "mam_cinema",
            "theatro_net", "ccbb_teatro_cinema",
            "istituto_italiano", "maze_jazz", "teatro_leblon", "clube_jazz_rival", "estacao_net"
        ]
        prompts_venues = {}

        for venue_id in venues_ids:
            config = self.prompt_loader.get_venue(venue_id, context)
            prompts_venues[venue_id] = self._build_prompt_from_config(config, context)

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # BUSCAS SEPARADAS PARA SÃBADOS OUTDOOR (dinÃ¢mico)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        start_date = SEARCH_CONFIG['start_date']
        end_date = SEARCH_CONFIG['end_date']
        saturdays = self._get_saturdays_in_period(start_date, end_date)
        saturday_prompts = []
        saturday_names = []

        for saturday in saturdays:
            saturday_date_str = saturday["date_str"]
            month_str = saturday["date"].strftime("%B").lower()
            prompt = self._build_saturday_outdoor_prompt(saturday_date_str, month_str)
            saturday_prompts.append(prompt)
            saturday_names.append(f"Outdoor SÃ¡bado {saturday_date_str}")

        logger.info(f"{self.log_prefix} ğŸ—“ï¸  {len(saturdays)} sÃ¡bados identificados no perÃ­odo: {[s['date_str'] for s in saturdays]}")

        total_prompts = len(categorias_ids) - 1 + len(saturday_prompts) + len(venues_ids)  # -1 para remover "outdoor" genÃ©rico
        logger.info(f"{self.log_prefix} âœ… {total_prompts} prompts criados com sucesso")

        try:
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # EXECUÃ‡ÃƒO PARALELA DAS MICRO-SEARCHES
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            logger.info(f"{self.log_prefix} Executando {total_prompts} micro-searches em paralelo...")

            # Preparar lista de searches (categorias + sÃ¡bados + venues)
            searches = [
                self._run_micro_search(prompts_categorias["jazz"], "Jazz"),
                self._run_micro_search(prompts_categorias["comedia"], "ComÃ©dia"),
                self._run_micro_search(prompts_categorias["musica_classica"], "MÃºsica ClÃ¡ssica"),
                # OUTDOOR: substituÃ­do por buscas separadas por sÃ¡bado
                self._run_micro_search(prompts_categorias["cinema"], "Cinema"),
                self._run_micro_search(prompts_categorias["feira_gastronomica"], "Feira GastronÃ´mica"),
                self._run_micro_search(prompts_categorias["feira_artesanato"], "Feira de Artesanato"),
            ]

            # Adicionar buscas de sÃ¡bados outdoor
            for i, saturday_prompt in enumerate(saturday_prompts):
                searches.append(self._run_micro_search(saturday_prompt, saturday_names[i]))

            # Adicionar buscas de venues
            searches.extend([
                self._run_micro_search(prompts_venues["casa_choro"], "Casa do Choro"),
                self._run_micro_search(prompts_venues["sala_cecilia"], "Sala CecÃ­lia Meireles"),
                self._run_micro_search(prompts_venues["teatro_municipal"], "Teatro Municipal"),
                self._run_micro_search(prompts_venues["artemis"], "Artemis"),
                self._run_micro_search(prompts_venues["ccbb"], "CCBB Rio"),
                self._run_micro_search(prompts_venues["oi_futuro"], "Oi Futuro"),
                self._run_micro_search(prompts_venues["ims"], "IMS"),
                self._run_micro_search(prompts_venues["parque_lage"], "Parque Lage"),
                self._run_micro_search(prompts_venues["ccjf"], "CCJF"),
                self._run_micro_search(prompts_venues["mam_cinema"], "MAM Cinema"),
                self._run_micro_search(prompts_venues["theatro_net"], "Theatro Net Rio"),
                self._run_micro_search(prompts_venues["ccbb_teatro_cinema"], "CCBB Teatro/Cinema"),
                self._run_micro_search(prompts_venues["istituto_italiano"], "Istituto Italiano"),
                self._run_micro_search(prompts_venues["maze_jazz"], "Maze Jazz Club"),
                self._run_micro_search(prompts_venues["teatro_leblon"], "Teatro do Leblon"),
                self._run_micro_search(prompts_venues["clube_jazz_rival"], "Clube do Jazz/Rival"),
                self._run_micro_search(prompts_venues["estacao_net"], "EstaÃ§Ã£o Net"),
            ])

            # Executar todas as buscas em paralelo
            results = await asyncio.gather(*searches)

            # Desempacotar resultados
            # Formato: [jazz, comedia, musica_classica, cinema, feira_gast, feira_art, sÃ¡bados..., venues...]
            result_jazz = results[0]
            result_comedia = results[1]
            result_musica_classica = results[2]
            result_cinema = results[3]
            result_feira_gastronomica = results[4]
            result_feira_artesanato = results[5]

            # Resultados dos sÃ¡bados outdoor (dinÃ¢mico) - consolidar todos
            saturday_results = results[6:6 + len(saturdays)]
            logger.info(f"ğŸ—“ï¸  Processando {len(saturday_results)} resultados de sÃ¡bados outdoor...")

            # Resultados dos venues (apÃ³s sÃ¡bados)
            venues_start_idx = 6 + len(saturdays)
            result_casa_choro = results[venues_start_idx]
            result_sala_cecilia = results[venues_start_idx + 1]
            result_teatro_municipal = results[venues_start_idx + 2]
            result_artemis = results[venues_start_idx + 3]
            result_ccbb = results[venues_start_idx + 4]
            result_oi_futuro = results[venues_start_idx + 5]
            result_ims = results[venues_start_idx + 6]
            result_parque_lage = results[venues_start_idx + 7]
            result_ccjf = results[venues_start_idx + 8]
            result_mam_cinema = results[venues_start_idx + 9]
            result_theatro_net = results[venues_start_idx + 10]
            result_ccbb_teatro_cinema = results[venues_start_idx + 11]
            result_istituto_italiano = results[venues_start_idx + 12]
            result_maze_jazz = results[venues_start_idx + 13]
            result_teatro_leblon = results[venues_start_idx + 14]
            result_clube_jazz_rival = results[venues_start_idx + 15]
            result_estacao_net = results[venues_start_idx + 16]

            logger.info(f"âœ“ Todas as {total_prompts} micro-searches concluÃ­das")

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # MERGE INTELIGENTE DOS RESULTADOS COM PYDANTIC
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            logger.info("ğŸ”— Fazendo merge dos resultados...")

            # Helper function: Clean markdown from JSON
            def clean_json_from_markdown(text: str) -> str:
                """Remove markdown code blocks and extra text from JSON responses.

                Handles cases like:
                - # Eventos na Sala CecÃ­lia Meireles\n\nCom base na busca...\n\n```json\n{...}\n```
                - Plain JSON with preamble text
                - Multiple markdown blocks (uses last one)
                """
                if not text or text.strip() == "":
                    return ""

                import re

                # Remove leading/trailing whitespace
                text = text.strip()

                # STEP 1: Try to find JSON within markdown code blocks
                # Pattern: ```json ... ``` or ``` ... ```
                code_block_pattern = r'```(?:json)?\s*([\s\S]*?)\s*```'
                matches = re.findall(code_block_pattern, text)
                if matches:
                    # Use the last match (usually the complete JSON)
                    text = matches[-1].strip()

                # STEP 2: Remove ANYTHING before the first { or [
                # This handles preamble text like headers, explanations, etc.
                json_start_brace = text.find('{')
                json_start_bracket = text.find('[')

                # Find the earliest valid JSON start
                valid_starts = [pos for pos in [json_start_brace, json_start_bracket] if pos != -1]
                if valid_starts:
                    json_start = min(valid_starts)
                    text = text[json_start:]

                # STEP 3: Remove ANYTHING after the last } or ]
                # Find matching closing bracket
                if text.startswith('{'):
                    # Find the last } that matches the structure
                    depth = 0
                    for i, char in enumerate(text):
                        if char == '{':
                            depth += 1
                        elif char == '}':
                            depth -= 1
                            if depth == 0:
                                text = text[:i+1]
                                break
                elif text.startswith('['):
                    # Find the last ] that matches the structure
                    depth = 0
                    for i, char in enumerate(text):
                        if char == '[':
                            depth += 1
                        elif char == ']':
                            depth -= 1
                            if depth == 0:
                                text = text[:i+1]
                                break

                return text.strip()

            # Helper function: Parse categoria com Pydantic
            def safe_parse_categoria(result_str: str, search_name: str) -> list[dict]:
                """Parse categoria usando Pydantic validation."""
                try:
                    if not result_str or result_str.strip() == "":
                        logger.warning(f"âš ï¸  Busca {search_name} retornou vazio")
                        return []
                    # Limpar markdown antes de parsear
                    clean_json = clean_json_from_markdown(result_str)
                    if not clean_json:
                        logger.warning(f"âš ï¸  Busca {search_name} retornou JSON vazio apÃ³s limpeza")
                        return []
                    # Use Pydantic para validar e parsear
                    resultado = ResultadoBuscaCategoria.model_validate_json(clean_json)
                    logger.info(f"âœ“ Busca {search_name}: {len(resultado.eventos)} eventos validados")
                    # Converter Pydantic models para dicts
                    return [evento.model_dump() for evento in resultado.eventos]
                except ValidationError as e:
                    logger.error(f"âŒ Schema invÃ¡lido na busca {search_name}:")
                    for error in e.errors():
                        logger.error(f"   â€¢ {error['loc']}: {error['msg']}")
                    logger.error(f"   ConteÃºdo (primeiros 200 chars): {result_str[:200]}")
                    return []
                except Exception as e:
                    logger.error(f"âŒ Erro inesperado na busca {search_name}: {e}")
                    return []

            # Helper function: Parse venue (formato diferente, mantÃ©m dict)
            def safe_parse_venue(result_str: str, venue_name: str) -> list[dict]:
                """Parse venue usando JSON simples (formato: {venue_name: [eventos]}).

                Inclui fallback com normalizaÃ§Ã£o unicode para lidar com acentuaÃ§Ã£o.
                """
                try:
                    import unicodedata

                    if not result_str or result_str.strip() == "":
                        logger.warning(f"âš ï¸  Busca {venue_name} retornou vazio")
                        return []
                    # Limpar markdown antes de parsear
                    clean_json = clean_json_from_markdown(result_str)
                    if not clean_json:
                        logger.warning(f"âš ï¸  Busca {venue_name} retornou JSON vazio apÃ³s limpeza")
                        return []
                    data = json.loads(clean_json)

                    # STEP 1: Tentar match exato primeiro
                    eventos = data.get(venue_name, [])

                    # STEP 2: Se nÃ£o encontrou, tentar com normalizaÃ§Ã£o unicode (fallback)
                    if not eventos and venue_name:
                        # Normalizar nome do venue esperado (NFD = decompor acentos)
                        normalized_expected = unicodedata.normalize('NFD', venue_name)

                        # Tentar encontrar chave com normalizaÃ§Ã£o
                        for key in data.keys():
                            normalized_key = unicodedata.normalize('NFD', key)
                            if normalized_key == normalized_expected:
                                eventos = data.get(key, [])
                                logger.info(
                                    f"âš™ï¸  Fallback unicode: '{key}' â†’ '{venue_name}' "
                                    f"({len(eventos)} eventos)"
                                )
                                break

                    if eventos:
                        logger.info(f"âœ“ Busca {venue_name}: {len(eventos)} eventos encontrados")
                    else:
                        logger.warning(f"âš ï¸  Nenhum evento encontrado para {venue_name} (chaves disponÃ­veis: {list(data.keys())})")

                    return eventos
                except json.JSONDecodeError as e:
                    logger.error(f"âŒ JSON invÃ¡lido na busca {venue_name}: {e}")
                    logger.error(f"   ConteÃºdo (primeiros 200 chars): {result_str[:200]}")
                    return []

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # MERGE JAZZ: Scraper Blue Note TEM PRIORIDADE sobre Perplexity
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            eventos_jazz = []

            # PASSO 1: Adicionar eventos do SCRAPER primeiro (prioridade alta - links oficiais)
            if blue_note_scraped:
                logger.info(f"ğŸ« [PRIORIDADE] Adicionando {len(blue_note_scraped)} eventos Blue Note do scraper oficial...")
                for scraped_event in blue_note_scraped:
                    # Converter para formato EventoCategoria
                    jazz_event = {
                        "titulo": scraped_event["titulo"],
                        "data": scraped_event["data"],
                        "horario": scraped_event["horario"],
                        "local": "Blue Note Rio - Av. AtlÃ¢ntica, 1910, Copacabana, Rio de Janeiro",
                        "preco": "Consultar link",
                        "link_ingresso": scraped_event["link"],
                        "descricao": None,  # SerÃ¡ enriquecido depois
                        "categoria": "Jazz"
                    }
                    eventos_jazz.append(jazz_event)
                    logger.debug(f"   âœ“ Scraper: {jazz_event['titulo']}")
                logger.info(f"âœ“ {len(eventos_jazz)} eventos do scraper Blue Note adicionados")

            # PASSO 2: Adicionar eventos do PERPLEXITY como complemento (apenas nÃ£o-duplicatas)
            eventos_jazz_perplexity = safe_parse_categoria(result_jazz, "Jazz")
            logger.debug(f"Jazz parsed from Perplexity - {len(eventos_jazz_perplexity)} eventos")

            if eventos_jazz_perplexity:
                duplicatas_perplexity = 0
                for perplexity_event in eventos_jazz_perplexity:
                    # Verificar duplicata por tÃ­tulo (case-insensitive)
                    if not any(e.get("titulo", "").lower() == perplexity_event.get("titulo", "").lower()
                               for e in eventos_jazz):
                        eventos_jazz.append(perplexity_event)
                        logger.debug(f"   âœ“ Perplexity: {perplexity_event.get('titulo')}")
                    else:
                        duplicatas_perplexity += 1
                        logger.debug(f"   â­ï¸  Duplicata do Perplexity ignorada (scraper tem prioridade): {perplexity_event.get('titulo')}")

                if duplicatas_perplexity > 0:
                    logger.info(f"â­ï¸  {duplicatas_perplexity} duplicatas do Perplexity ignoradas (scraper tem prioridade)")

            logger.info(f"âœ“ Total de eventos Jazz apÃ³s merge: {len(eventos_jazz)} eventos")

            eventos_comedia = safe_parse_categoria(result_comedia, "ComÃ©dia")
            logger.debug(f"ComÃ©dia parsed - {len(eventos_comedia)} eventos")

            eventos_musica_classica = safe_parse_categoria(result_musica_classica, "MÃºsica ClÃ¡ssica")
            logger.debug(f"MÃºsica ClÃ¡ssica parsed - {len(eventos_musica_classica)} eventos")

            # Processar eventos outdoor dos sÃ¡bados (consolidar todos os resultados)
            eventos_outdoor = []
            for i, saturday_result in enumerate(saturday_results):
                saturday_date = saturdays[i]["date_str"]
                eventos_sab = safe_parse_categoria(saturday_result, "Outdoor/Parques")
                if eventos_sab:
                    logger.info(f"   âœ“ SÃ¡bado {saturday_date}: {len(eventos_sab)} eventos outdoor")
                    eventos_outdoor.extend(eventos_sab)
                else:
                    logger.debug(f"   âš ï¸  SÃ¡bado {saturday_date}: 0 eventos outdoor")

            logger.info(f"âœ“ Total eventos outdoor (todos os sÃ¡bados): {len(eventos_outdoor)} eventos")

            eventos_cinema = safe_parse_categoria(result_cinema, "Cinema")
            logger.debug(f"Cinema parsed - {len(eventos_cinema)} eventos")

            eventos_feira_gastronomica = safe_parse_categoria(result_feira_gastronomica, "Feira GastronÃ´mica")
            logger.debug(f"Feira GastronÃ´mica parsed - {len(eventos_feira_gastronomica)} eventos")

            eventos_feira_artesanato = safe_parse_categoria(result_feira_artesanato, "Feira de Artesanato")
            logger.debug(f"Feira de Artesanato parsed - {len(eventos_feira_artesanato)} eventos")

            # Merge eventos gerais (todas as 7 categorias)
            todos_eventos_gerais = (
                eventos_jazz +
                eventos_comedia +
                eventos_musica_classica +
                eventos_outdoor +
                eventos_cinema +
                eventos_feira_gastronomica +
                eventos_feira_artesanato
            )

            # OTIMIZAÃ‡ÃƒO: DeduplicaÃ§Ã£o precoce ANTES de validaÃ§Ã£o/enriquecimento
            # Economiza chamadas de API processando apenas eventos Ãºnicos
            eventos_antes_dedup = len(todos_eventos_gerais)
            todos_eventos_gerais = deduplicate_events(todos_eventos_gerais)
            eventos_removidos = eventos_antes_dedup - len(todos_eventos_gerais)
            if eventos_removidos > 0:
                logger.info(
                    f"ğŸ”„ DeduplicaÃ§Ã£o precoce: {eventos_removidos} eventos duplicados removidos "
                    f"({eventos_antes_dedup} â†’ {len(todos_eventos_gerais)})"
                )

            # Criar estrutura de eventos gerais
            eventos_gerais_merged = {"eventos": todos_eventos_gerais}

            # Parse eventos de venues
            eventos_casa_choro = safe_parse_venue(result_casa_choro, "Casa do Choro")
            logger.debug(f"Casa do Choro parsed - {len(eventos_casa_choro)} eventos")

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # MERGE SALA CECÃLIA MEIRELES: Scraper TEM PRIORIDADE sobre Perplexity
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            eventos_sala_cecilia = []

            # PASSO 1: Adicionar eventos do SCRAPER primeiro (prioridade alta - links oficiais)
            if cecilia_meireles_scraped:
                logger.info(f"ğŸ¼ [PRIORIDADE] Adicionando {len(cecilia_meireles_scraped)} eventos Sala CecÃ­lia Meireles do scraper oficial...")
                for scraped_event in cecilia_meireles_scraped:
                    # Converter para formato EventoVenue
                    cecilia_event = {
                        "titulo": scraped_event["titulo"],
                        "data": scraped_event["data"],
                        "horario": scraped_event["horario"],
                        "local": "Sala CecÃ­lia Meireles - Rua da Lapa, 47, Centro, Rio de Janeiro",
                        "preco": "Consultar link",
                        "link_ingresso": scraped_event["link"],
                        "descricao": None,  # SerÃ¡ enriquecido depois
                        "venue": "Sala CecÃ­lia Meireles"
                    }
                    eventos_sala_cecilia.append(cecilia_event)
                    logger.debug(f"   âœ“ Scraper: {cecilia_event['titulo']}")
                logger.info(f"âœ“ {len(eventos_sala_cecilia)} eventos do scraper Sala CecÃ­lia Meireles adicionados")

            # PASSO 2: Adicionar eventos do PERPLEXITY como complemento (apenas nÃ£o-duplicatas)
            eventos_sala_cecilia_perplexity = safe_parse_venue(result_sala_cecilia, "Sala CecÃ­lia Meireles")
            logger.debug(f"Sala CecÃ­lia Meireles parsed from Perplexity - {len(eventos_sala_cecilia_perplexity)} eventos")

            if eventos_sala_cecilia_perplexity:
                duplicatas_perplexity = 0
                for perplexity_event in eventos_sala_cecilia_perplexity:
                    # Verificar duplicata por tÃ­tulo (case-insensitive)
                    if not any(e.get("titulo", "").lower() == perplexity_event.get("titulo", "").lower()
                               for e in eventos_sala_cecilia):
                        eventos_sala_cecilia.append(perplexity_event)
                        logger.debug(f"   âœ“ Perplexity: {perplexity_event.get('titulo')}")
                    else:
                        duplicatas_perplexity += 1
                        logger.debug(f"   â­ï¸  Duplicata do Perplexity ignorada (scraper tem prioridade): {perplexity_event.get('titulo')}")

                if duplicatas_perplexity > 0:
                    logger.info(f"â­ï¸  {duplicatas_perplexity} duplicatas do Perplexity ignoradas (scraper tem prioridade)")

            logger.info(f"âœ“ Total de eventos Sala CecÃ­lia Meireles apÃ³s merge: {len(eventos_sala_cecilia)} eventos")

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # MERGE TEATRO MUNICIPAL: Scraper TEM PRIORIDADE sobre Perplexity
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            eventos_teatro_municipal = []

            # PASSO 1: Adicionar eventos do SCRAPER primeiro (prioridade alta - links oficiais)
            if teatro_municipal_scraped:
                logger.info(f"ğŸ­ [PRIORIDADE] Adicionando {len(teatro_municipal_scraped)} eventos Teatro Municipal do scraper oficial...")
                for scraped_event in teatro_municipal_scraped:
                    # Converter para formato EventoVenue
                    municipal_event = {
                        "titulo": scraped_event["titulo"],
                        "data": scraped_event["data"],
                        "horario": scraped_event["horario"],
                        "local": "Teatro Municipal do Rio de Janeiro - PraÃ§a Floriano, s/n, Centro, Rio de Janeiro",
                        "preco": "Consultar link",
                        "link_ingresso": scraped_event["link"],
                        "descricao": None,  # SerÃ¡ enriquecido depois
                        "venue": "Teatro Municipal do Rio de Janeiro"
                    }
                    eventos_teatro_municipal.append(municipal_event)
                    logger.debug(f"   âœ“ Scraper: {municipal_event['titulo']}")
                logger.info(f"âœ“ {len(eventos_teatro_municipal)} eventos do scraper Teatro Municipal adicionados")

            # PASSO 2: Adicionar eventos do PERPLEXITY como complemento (apenas nÃ£o-duplicatas)
            eventos_teatro_municipal_perplexity = safe_parse_venue(result_teatro_municipal, "Teatro Municipal do Rio de Janeiro")
            logger.debug(f"Teatro Municipal parsed from Perplexity - {len(eventos_teatro_municipal_perplexity)} eventos")

            if eventos_teatro_municipal_perplexity:
                duplicatas_perplexity = 0
                for perplexity_event in eventos_teatro_municipal_perplexity:
                    # Verificar duplicata por tÃ­tulo (case-insensitive)
                    if not any(e.get("titulo", "").lower() == perplexity_event.get("titulo", "").lower()
                               for e in eventos_teatro_municipal):
                        eventos_teatro_municipal.append(perplexity_event)
                        logger.debug(f"   âœ“ Perplexity: {perplexity_event.get('titulo')}")
                    else:
                        duplicatas_perplexity += 1
                        logger.debug(f"   â­ï¸  Duplicata do Perplexity ignorada (scraper tem prioridade): {perplexity_event.get('titulo')}")

                if duplicatas_perplexity > 0:
                    logger.info(f"â­ï¸  {duplicatas_perplexity} duplicatas do Perplexity ignoradas (scraper tem prioridade)")

            logger.info(f"âœ“ Total de eventos Teatro Municipal apÃ³s merge: {len(eventos_teatro_municipal)} eventos")

            eventos_artemis = safe_parse_venue(result_artemis, "Artemis - TorrefaÃ§Ã£o Artesanal e Cafeteria")
            logger.debug(f"Artemis parsed - {len(eventos_artemis)} eventos")

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # MERGE CCBB: Scraper TEM PRIORIDADE sobre Perplexity
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            eventos_ccbb = []

            # PASSO 1: Adicionar eventos do SCRAPER primeiro (prioridade alta - links oficiais)
            if ccbb_scraped:
                logger.info(f"ğŸ¨ [PRIORIDADE] Adicionando {len(ccbb_scraped)} eventos CCBB do scraper oficial...")
                for scraped_event in ccbb_scraped:
                    # Converter para formato EventoVenue
                    ccbb_event = {
                        "titulo": scraped_event["titulo"],
                        "data": scraped_event["data"],
                        "horario": scraped_event["horario"],
                        "local": "CCBB Rio - Centro Cultural Banco do Brasil - Rua Primeiro de MarÃ§o, 66, Centro, Rio de Janeiro",
                        "preco": "Consultar link",
                        "link_ingresso": scraped_event["link"],
                        "descricao": None,  # SerÃ¡ enriquecido depois
                        "venue": "CCBB Rio - Centro Cultural Banco do Brasil"
                    }
                    eventos_ccbb.append(ccbb_event)
                    logger.debug(f"   âœ“ Scraper: {ccbb_event['titulo']}")
                logger.info(f"âœ“ {len(eventos_ccbb)} eventos do scraper CCBB adicionados")

            # PASSO 2: Adicionar eventos do PERPLEXITY como complemento (apenas nÃ£o-duplicatas)
            eventos_ccbb_perplexity = safe_parse_venue(result_ccbb, "CCBB Rio - Centro Cultural Banco do Brasil")
            logger.debug(f"CCBB Rio parsed from Perplexity - {len(eventos_ccbb_perplexity)} eventos")

            if eventos_ccbb_perplexity:
                duplicatas_perplexity = 0
                for perplexity_event in eventos_ccbb_perplexity:
                    # Verificar duplicata por tÃ­tulo (case-insensitive)
                    if not any(e.get("titulo", "").lower() == perplexity_event.get("titulo", "").lower()
                               for e in eventos_ccbb):
                        eventos_ccbb.append(perplexity_event)
                        logger.debug(f"   âœ“ Perplexity: {perplexity_event.get('titulo')}")
                    else:
                        duplicatas_perplexity += 1
                        logger.debug(f"   â­ï¸  Duplicata do Perplexity ignorada (scraper tem prioridade): {perplexity_event.get('titulo')}")

                if duplicatas_perplexity > 0:
                    logger.info(f"â­ï¸  {duplicatas_perplexity} duplicatas do Perplexity ignoradas (scraper tem prioridade)")

            logger.info(f"âœ“ Total de eventos CCBB apÃ³s merge: {len(eventos_ccbb)} eventos")

            eventos_oi_futuro = safe_parse_venue(result_oi_futuro, "Oi Futuro")
            logger.debug(f"Oi Futuro parsed - {len(eventos_oi_futuro)} eventos")

            eventos_ims = safe_parse_venue(result_ims, "IMS - Instituto Moreira Salles")
            logger.debug(f"IMS parsed - {len(eventos_ims)} eventos")

            eventos_parque_lage = safe_parse_venue(result_parque_lage, "Parque Lage")
            logger.debug(f"Parque Lage parsed - {len(eventos_parque_lage)} eventos")

            eventos_ccjf = safe_parse_venue(result_ccjf, "CCJF - Centro Cultural JustiÃ§a Federal")
            logger.debug(f"CCJF parsed - {len(eventos_ccjf)} eventos")

            eventos_mam_cinema = safe_parse_venue(result_mam_cinema, "MAM Cinema")
            logger.debug(f"MAM Cinema parsed - {len(eventos_mam_cinema)} eventos")

            eventos_theatro_net = safe_parse_venue(result_theatro_net, "Theatro Net Rio")
            logger.debug(f"Theatro Net Rio parsed - {len(eventos_theatro_net)} eventos")

            eventos_ccbb_teatro_cinema = safe_parse_venue(result_ccbb_teatro_cinema, "CCBB Teatro e Cinema")
            logger.debug(f"CCBB Teatro e Cinema parsed - {len(eventos_ccbb_teatro_cinema)} eventos")

            eventos_istituto_italiano = safe_parse_venue(result_istituto_italiano, "Istituto Italiano di Cultura")
            logger.debug(f"Istituto Italiano parsed - {len(eventos_istituto_italiano)} eventos")

            eventos_maze_jazz = safe_parse_venue(result_maze_jazz, "Maze Jazz Club")
            logger.debug(f"Maze Jazz Club parsed - {len(eventos_maze_jazz)} eventos")

            eventos_teatro_leblon = safe_parse_venue(result_teatro_leblon, "Teatro do Leblon")
            logger.debug(f"Teatro do Leblon parsed - {len(eventos_teatro_leblon)} eventos")

            eventos_clube_jazz_rival = safe_parse_venue(result_clube_jazz_rival, "Clube do Jazz / Teatro Rival")
            logger.debug(f"Clube do Jazz/Rival parsed - {len(eventos_clube_jazz_rival)} eventos")

            eventos_estacao_net = safe_parse_venue(result_estacao_net, "EstaÃ§Ã£o Net (Ipanema e Botafogo)")
            logger.debug(f"EstaÃ§Ã£o Net parsed - {len(eventos_estacao_net)} eventos")

            # Criar estrutura de eventos de venues
            eventos_locais_merged = {
                "Casa do Choro": eventos_casa_choro,
                "Sala CecÃ­lia Meireles": eventos_sala_cecilia,
                "Teatro Municipal do Rio de Janeiro": eventos_teatro_municipal,
                "Artemis - TorrefaÃ§Ã£o Artesanal e Cafeteria": eventos_artemis,
                "CCBB Rio - Centro Cultural Banco do Brasil": eventos_ccbb,
                "Oi Futuro": eventos_oi_futuro,
                "IMS - Instituto Moreira Salles": eventos_ims,
                "Parque Lage": eventos_parque_lage,
                "CCJF - Centro Cultural JustiÃ§a Federal": eventos_ccjf,
                "MAM Cinema": eventos_mam_cinema,
                "Theatro Net Rio": eventos_theatro_net,
                "CCBB Teatro e Cinema": eventos_ccbb_teatro_cinema,
                "Istituto Italiano di Cultura": eventos_istituto_italiano,
                "Maze Jazz Club": eventos_maze_jazz,
                "Teatro do Leblon": eventos_teatro_leblon,
                "Clube do Jazz / Teatro Rival": eventos_clube_jazz_rival,
                "EstaÃ§Ã£o Net (Ipanema e Botafogo)": eventos_estacao_net,
            }

            total_venues_before = sum(len(v) for v in eventos_locais_merged.values())
            logger.info(
                f"âœ“ Merge concluÃ­do: {len(todos_eventos_gerais)} eventos gerais, "
                f"{total_venues_before} eventos de venues"
            )

            # Normalizar nomes de venues (consolidar CCBB Teatro I/II/III, etc.)
            logger.info(f"ğŸ”— Normalizando nomes de venues...")
            eventos_locais_merged = self._normalize_venue_names(eventos_locais_merged)

            # Aplicar limitaÃ§Ã£o de eventos por venue
            logger.info(f"ğŸ“Š Aplicando limitaÃ§Ã£o de {MAX_EVENTS_PER_VENUE} eventos por venue...")
            eventos_locais_merged = self._limit_events_per_venue(eventos_locais_merged)

            total_venues_after = sum(len(v) for v in eventos_locais_merged.values())
            if total_venues_after < total_venues_before:
                logger.info(
                    f"ğŸ“Š LimitaÃ§Ã£o aplicada: {total_venues_before} eventos â†’ {total_venues_after} eventos "
                    f"({total_venues_before - total_venues_after} removidos)"
                )

            # Retornar no formato compatÃ­vel com o resto do sistema
            try:
                json_geral = json.dumps(eventos_gerais_merged, ensure_ascii=False)
                json_especial = json.dumps(eventos_locais_merged, ensure_ascii=False)

                result = {
                    "perplexity_geral": json_geral,
                    "perplexity_especial": json_especial,
                    "search_timestamp": datetime.now().isoformat(),
                }
                return result
            except Exception as json_error:
                logger.error(f"âŒ Erro na serializaÃ§Ã£o JSON: {json_error}")
                import traceback
                traceback.print_exc()
                raise

        except Exception as e:
            logger.error(f"âŒ ERRO CRÃTICO nas micro-searches: {type(e).__name__}: {e}")
            logger.error("ğŸ“ Local do erro:")
            import traceback
            import sys
            exc_type, exc_value, exc_traceback = sys.exc_info()

            # Logar o traceback completo
            logger.error("=== TRACEBACK COMPLETO ===")
            traceback.print_exc()
            logger.error("=========================")

            # Logar informaÃ§Ãµes sobre onde o erro ocorreu
            if exc_traceback:
                frame = exc_traceback.tb_frame
                lineno = exc_traceback.tb_lineno
                filename = frame.f_code.co_filename
                logger.error(f"Arquivo: {filename}, Linha: {lineno}")
                logger.error(f"FunÃ§Ã£o: {frame.f_code.co_name}")

            # Retornar JSONs vazios como fallback (para nÃ£o quebrar o pipeline)
            logger.warning("âš ï¸  Retornando JSONs vazios como fallback")
            return {
                "perplexity_geral": "{}",
                "perplexity_especial": "{}",
                "search_timestamp": datetime.now().isoformat(),
            }

    def _find_event_ticket_link_batch(self, events_batch: list[dict]) -> dict[str, str]:
        """Busca links de mÃºltiplos eventos em uma Ãºnica chamada (batch)."""
        if not events_batch:
            return {}

        # Construir prompt com lista de eventos
        eventos_texto = []
        for i, event in enumerate(events_batch, 1):
            titulo = event.get("titulo", "")
            data = event.get("data", "")
            local = event.get("local", "")
            eventos_texto.append(f"{i}. {titulo} | Data: {data} | Local: {local}")

        # Usar PromptBuilder para construir prompt estruturado
        prompt = (
            PromptBuilder()
            .add_header(
                "MISSÃƒO CRÃTICA",
                f"Encontrar links ESPECÃFICOS de venda/informaÃ§Ãµes para estes {len(events_batch)} eventos no Rio de Janeiro."
            )
            .add_section("EVENTOS", "\n".join(eventos_texto))
            .add_raw("\nESTRATÃ‰GIA DE BUSCA OBRIGATÃ“RIA (siga esta ordem):\n\nPara CADA evento:")
            .add_numbered_list(
                "",
                [
                    """**PRIORIDADE MÃXIMA - Site Oficial do Venue**:
   - Blue Note Rio â†’ acesse bluenoterio.com e busque na agenda/programaÃ§Ã£o
   - Teatro Municipal â†’ acesse theatromunicipal.rj.gov.br
   - Sala CecÃ­lia Meirelles â†’ acesse salaceliciameireles.com.br
   - Casa do Choro â†’ acesse casadochoro.com.br/agenda
   - Outros venues â†’ busque "[nome venue] agenda programaÃ§Ã£o\"""",
                    """**Plataformas de Ingressos** (use termos EXATOS):
   - Sympla: busque "site:sympla.com.br [titulo evento completo] rio"
   - Ingresso.com: busque "site:ingresso.com [titulo evento completo]"
   - Eventbrite: busque "site:eventbrite.com.br [titulo evento completo]"
   - Bilheteria Digital, Ticket360, Uhuu""",
                    """**Redes Sociais/Instagram** (Ãºltimo recurso):
   - Busque Instagram oficial do venue com link na bio ou stories
   - Posts recentes sobre o evento especÃ­fico"""
                ],
                emoji_prefix=True
            )
            .add_criteria({
                "ACEITE APENAS": [
                    "URLs que levam DIRETAMENTE Ã  pÃ¡gina do evento especÃ­fico",
                    "URLs com ID Ãºnico, slug do evento, ou data na URL",
                    """Exemplos vÃ¡lidos:
     * sympla.com.br/evento/nome-evento-123456
     * bluenoterio.com/shows/artista-data-20250115
     * eventbrite.com.br/e/titulo-evento-tickets-789012"""
                ],
                "REJEITE ABSOLUTAMENTE": [
                    "Homepages: bluenoterio.com, casadochoro.com.br",
                    "PÃ¡ginas de listagem: /agenda, /shows, /eventos, /programacao",
                    "URLs genÃ©ricas sem identificador do evento",
                    "Links de redes sociais (exceto se for o ÃšNICO link disponÃ­vel)"
                ]
            }, title="CRITÃ‰RIOS DE ACEITAÃ‡ÃƒO (seja RIGOROSO)")
            .add_numbered_list(
                "VALIDAÃ‡ÃƒO FINAL:\nAntes de retornar cada link",
                [
                    "Confirme que a URL contÃ©m elemento Ãºnico (ID, nome, data)",
                    "Verifique que nÃ£o Ã© pÃ¡gina genÃ©rica",
                    "Se tiver dÃºvida, retorne null"
                ]
            )
            .add_json_example(
                {
                    "1": "https://url-especifica-evento-1.com/... ou null",
                    "2": "https://url-especifica-evento-2.com/... ou null"
                },
                "FORMATO JSON (sem comentÃ¡rios)"
            )
            .add_raw("âš ï¸ IMPORTANTE: Prefira retornar null do que um link genÃ©rico. Links ruins serÃ£o rejeitados na validaÃ§Ã£o.")
            .build()
        )

        try:
            response = self.search_agent.run(prompt)

            # Usar safe_json_parse para extraÃ§Ã£o consistente
            from utils.json_helpers import safe_json_parse
            links_map = safe_json_parse(
                response.content,
                default={}
            )

            # Converter chaves para int se necessÃ¡rio e validar formato
            result = {}
            for key, value in links_map.items():
                # Validar que o link nÃ£o Ã© genÃ©rico
                if value and value != "null" and isinstance(value, str):
                    # Checar se nÃ£o Ã© link genÃ©rico bÃ¡sico
                    generic_endings = ['/shows/', '/eventos/', '/agenda/', '/programacao/', '/calendar/']
                    is_generic = any(value.rstrip('/').endswith(ending.rstrip('/')) for ending in generic_endings)

                    # TambÃ©m verificar se Ã© apenas homepage (sem path especÃ­fico)
                    from urllib.parse import urlparse
                    parsed = urlparse(value)
                    path = parsed.path.rstrip('/')

                    if is_generic or not path or path == '/':
                        logger.warning(f"   âš ï¸ Link genÃ©rico rejeitado: {value}")
                        result[str(key)] = None
                    else:
                        result[str(key)] = value
                else:
                    result[str(key)] = None

            return result

        except Exception as e:
            logger.error(f"Erro na busca batch de links: {e}")
            return {}

    def _search_missing_links(self, events: list[dict]) -> list[dict]:
        """Busca links para eventos que nÃ£o tÃªm link, processando em batches."""
        # Identificar eventos sem link
        events_without_links = []
        events_indices = []

        for i, event in enumerate(events):
            if not event.get("link_ingresso"):
                events_without_links.append(event)
                events_indices.append(i)

        if not events_without_links:
            logger.info("Todos os eventos jÃ¡ possuem links")
            return events

        logger.info(f"ğŸ”— Buscando links para {len(events_without_links)} eventos sem link...")

        # Processar em batches de 5
        batch_size = 5
        total_found = 0

        for batch_start in range(0, len(events_without_links), batch_size):
            batch_end = min(batch_start + batch_size, len(events_without_links))
            batch = events_without_links[batch_start:batch_end]

            logger.info(f"   Processando batch {batch_start//batch_size + 1} ({len(batch)} eventos)...")

            # Buscar links para este batch
            links_map = self._find_event_ticket_link_batch(batch)

            # Atribuir links encontrados
            for local_idx, event in enumerate(batch):
                batch_key = str(local_idx + 1)
                if batch_key in links_map and links_map[batch_key]:
                    event["link_ingresso"] = links_map[batch_key]
                    event["link_source"] = "busca_complementar_batch"
                    total_found += 1
                    logger.info(f"   âœ“ Link encontrado para: {event.get('titulo')}")

        logger.info(f"âœ“ Busca complementar concluÃ­da: {total_found}/{len(events_without_links)} links encontrados")
        return events

    def _filter_excluded_events(self, events: list[dict], category_name: str = "") -> list[dict]:
        """Filtra eventos que contÃªm palavras de exclusÃ£o no tÃ­tulo ou descriÃ§Ã£o.

        Args:
            events: Lista de eventos para filtrar
            category_name: Nome da categoria/venue (para logging)

        Returns:
            Lista de eventos filtrados (sem eventos que contÃªm keywords de exclusÃ£o)
        """
        from config import EVENT_CATEGORIES, GLOBAL_EXCLUDE_KEYWORDS

        # Iniciar com exclusÃµes GLOBAIS (infantil, LGBTQ+, etc) - aplicadas a TODOS os eventos
        exclude_keywords = list(GLOBAL_EXCLUDE_KEYWORDS)

        # Adicionar exclusÃµes especÃ­ficas de outdoor (shows mainstream) se aplicÃ¡vel
        outdoor_exclude = EVENT_CATEGORIES.get("outdoor_parques", {}).get("exclude", [])
        if outdoor_exclude:
            exclude_keywords.extend(outdoor_exclude)

        if not exclude_keywords:
            return events

        filtered = []
        removed_count = 0

        for event in events:
            titulo = event.get("titulo", "").lower()
            descricao_raw = event.get("descricao", "") or ""  # Handle None values
            descricao = descricao_raw.lower()
            combined_text = f"{titulo} {descricao}"

            # Verificar se contÃ©m alguma palavra de exclusÃ£o
            matched_keyword = None
            for keyword in exclude_keywords:
                if keyword.lower() in combined_text:
                    matched_keyword = keyword
                    break

            if matched_keyword:
                removed_count += 1
                logger.info(f"   âŒ Evento filtrado ({category_name}): '{event.get('titulo')}' [match: '{matched_keyword}']")
            else:
                filtered.append(event)

        if removed_count > 0:
            logger.info(f"âœ“ Filtro de exclusÃ£o aplicado em {category_name}: {removed_count} eventos removidos, {len(filtered)} mantidos")

        return filtered

    def process_with_llm(self, raw_events: dict[str, Any]) -> str:
        """Combina e limpa resultados das duas buscas Perplexity."""
        logger.info("Combinando dados das 2 buscas Perplexity...")

        # Extrair dados das duas buscas
        data_geral = raw_events.get("perplexity_geral", "{}")
        data_especial = raw_events.get("perplexity_especial", "{}")

        # Usar clean_json_response do json_helpers (centralizado)
        from utils.json_helpers import clean_json_response
        data_geral_clean = clean_json_response(data_geral)
        data_especial_clean = clean_json_response(data_especial)

        # Combinar em um Ãºnico JSON
        combined = f'{{"eventos_gerais": {data_geral_clean}, "eventos_locais_especiais": {data_especial_clean}}}'

        logger.info("Dados combinados das 2 buscas")

        # Parsear para aplicar busca complementar de links
        try:
            combined_data = json.loads(combined)

            # Extrair todos os eventos para busca complementar
            all_events = []

            # Eventos gerais
            if "eventos_gerais" in combined_data and "eventos" in combined_data["eventos_gerais"]:
                all_events.extend(combined_data["eventos_gerais"]["eventos"])

            # Eventos de locais especiais
            if "eventos_locais_especiais" in combined_data:
                for local_name, local_events in combined_data["eventos_locais_especiais"].items():
                    if isinstance(local_events, list):
                        all_events.extend([e for e in local_events if isinstance(e, dict)])

            # Aplicar busca complementar de links
            if all_events:
                self._search_missing_links(all_events)

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # APLICAR FILTRO DE EXCLUSÃƒO (remover samba, axÃ©, mainstream)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            logger.info("ğŸ” Aplicando filtro de exclusÃ£o...")

            # Filtrar eventos gerais (categorias: Jazz, Teatro-ComÃ©dia, Outdoor-FimDeSemana)
            if "eventos_gerais" in combined_data and "eventos" in combined_data["eventos_gerais"]:
                original_count = len(combined_data["eventos_gerais"]["eventos"])
                combined_data["eventos_gerais"]["eventos"] = self._filter_excluded_events(
                    combined_data["eventos_gerais"]["eventos"],
                    "eventos_gerais"
                )
                final_count = len(combined_data["eventos_gerais"]["eventos"])
                logger.info(f"ğŸ“Š Eventos gerais: {original_count} â†’ {final_count} (removidos: {original_count - final_count})")

            # Filtrar eventos de locais especiais (Casa do Choro, Sala CecÃ­lia, Teatro Municipal, Artemis)
            if "eventos_locais_especiais" in combined_data:
                for local_name, local_events in combined_data["eventos_locais_especiais"].items():
                    if isinstance(local_events, list) and local_events:
                        original_count = len(local_events)
                        combined_data["eventos_locais_especiais"][local_name] = self._filter_excluded_events(
                            local_events,
                            local_name
                        )
                        final_count = len(combined_data["eventos_locais_especiais"][local_name])
                        if original_count != final_count:
                            logger.info(f"ğŸ“Š {local_name}: {original_count} â†’ {final_count} (removidos: {original_count - final_count})")

            logger.info("âœ… Filtro de exclusÃ£o aplicado com sucesso")

            # Retornar JSON atualizado
            return json.dumps(combined_data, ensure_ascii=False, indent=2)

        except json.JSONDecodeError as e:
            logger.error(f"Erro ao parsear JSON combinado: {e}")
            return combined
