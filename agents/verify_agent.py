"""Agente de verifica√ß√£o e valida√ß√£o de eventos."""

import asyncio
import json
import logging
import re
from datetime import datetime, timedelta
from typing import Any

import httpx
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from tenacity import (
    retry,
    retry_if_exception_type,
    stop_after_attempt,
    wait_exponential,
)

from config import (
    HTTP_TIMEOUT,
    MAX_RETRIES,
    MODELS,
    OPENROUTER_API_KEY,
    OPENROUTER_BASE_URL,
    SEARCH_CONFIG,
)

logger = logging.getLogger(__name__)


class VerifyAgent:
    """Agente respons√°vel por verificar e validar informa√ß√µes de eventos."""

    def __init__(self):
        self.agent = Agent(
            name="Event Verification Agent",
            model=OpenAIChat(
                id=MODELS["verify"],  # Claude Sonnet para verifica√ß√£o rigorosa
                api_key=OPENROUTER_API_KEY,
                base_url=OPENROUTER_BASE_URL,
            ),
            description="Agente especializado em verificar e validar informa√ß√µes de eventos",
            instructions=[
                "Verificar se as datas dos eventos est√£o no per√≠odo correto "
                f"({SEARCH_CONFIG['start_date'].strftime('%d/%m/%Y')} a {SEARCH_CONFIG['end_date'].strftime('%d/%m/%Y')})",
                "Validar se os links de compra s√£o v√°lidos e acess√≠veis",
                "Identificar e remover eventos duplicados",
                "Confirmar se eventos de com√©dia n√£o s√£o infantis",
                "Verificar consist√™ncia de informa√ß√µes (data/hora/local/pre√ßo)",
                "Enriquecer descri√ß√µes quando necess√°rio",
                "Validar se eventos ao ar livre s√£o realmente em fim de semana",
                "Marcar eventos com baixa confiabilidade para revis√£o",
            ],
            markdown=True,
        )

    def _is_generic_link(self, url: str) -> bool:
        """Detecta se um link √© gen√©rico (p√°gina de busca/categoria/listagem).

        Args:
            url: URL a verificar

        Returns:
            True se o link for gen√©rico (n√£o espec√≠fico de um evento)
        """
        if not url or not isinstance(url, str):
            return False

        # Padr√µes de URLs gen√©ricas
        generic_patterns = [
            r'/eventos/[^/]+\?',  # /eventos/categoria?params
            r'/eventos\?',         # /eventos?params
            r'/busca\?',          # /busca?query=
            r'/search\?',         # /search?q=
            r'[?&]city=',         # query param de cidade
            r'[?&]partnership=',  # query param de partnership
            r'/d/brazil--',       # eventbrite listings
            r'/eventos/rio-de-janeiro',  # p√°ginas de listagem por cidade
            r'/events/rio-de-janeiro',   # p√°ginas de listagem por cidade
        ]

        for pattern in generic_patterns:
            if re.search(pattern, url, re.IGNORECASE):
                return True

        # Verificar se URL √© muito curta (provavelmente gen√©rica)
        # Ex: ingresso.com/eventos vs ingresso.com/evento/nome-evento-123456
        path = url.split('?')[0]  # Remover query params
        path_parts = [p for p in path.split('/') if p and p not in ['http:', 'https:', '']]

        # URL espec√≠fica geralmente tem pelo menos 3 partes: dominio/tipo/identificador
        if len(path_parts) < 3:
            # Exce√ß√µes: alguns dom√≠nios t√™m estrutura diferente
            if not any(domain in url.lower() for domain in ['bluenote', 'casadeshow', 'teatro']):
                return True

        return False

    async def verify_events(self, events_json: str) -> dict[str, Any]:
        """Verifica e valida eventos extra√≠dos pelo agente de busca."""
        logger.info("Iniciando verifica√ß√£o de eventos...")

        try:
            events_data = json.loads(events_json) if isinstance(events_json, str) else events_json
        except json.JSONDecodeError:
            logger.error("Erro ao decodificar JSON de eventos")
            return {"verified_events": [], "rejected_events": [], "warnings": ["JSON inv√°lido"]}

        # Validar links em paralelo (valida√ß√£o b√°sica)
        events_with_link_validation = await self._validate_links(events_data)

        # Processar com LLM para verifica√ß√£o inteligente (primeira camada)
        verified_data = self._verify_with_llm(events_with_link_validation)

        # NOVA CAMADA: Valida√ß√£o individual rigorosa com ValidationAgent
        logger.info("Iniciando valida√ß√£o individual rigorosa...")
        from agents.validation_agent import ValidationAgent

        validation_agent = ValidationAgent()
        individual_validation = await validation_agent.validate_events_batch(
            verified_data.get("verified_events", [])
        )

        # Combinar resultados
        final_verified = individual_validation["validated_events"]
        final_rejected = (
            verified_data.get("rejected_events", [])
            + individual_validation["rejected_events"]
        )
        final_warnings = (
            verified_data.get("warnings", [])
            + individual_validation["validation_warnings"]
        )

        logger.info(
            f"Verifica√ß√£o conclu√≠da. Eventos finais aprovados: {len(final_verified)} "
            f"(rejeitados na valida√ß√£o individual: {len(individual_validation['rejected_events'])})"
        )

        return {
            "verified_events": final_verified,
            "rejected_events": final_rejected,
            "warnings": final_warnings,
            "duplicates_removed": verified_data.get("duplicates_removed", []),
        }

    @retry(
        stop=stop_after_attempt(MAX_RETRIES),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type((
            httpx.TimeoutException,
            httpx.ConnectError,
            httpx.ReadTimeout,
        )),
        reraise=True,
    )
    async def _validate_single_link(
        self, client: httpx.AsyncClient, link: str, attempt_num: int = 1
    ) -> dict:
        """Valida um √∫nico link com retry autom√°tico para erros tempor√°rios."""
        logger.info(f"Validando link (tentativa {attempt_num}): {link}")
        response = await client.head(link, timeout=10)
        return {
            "valid": 200 <= response.status_code < 400,
            "status_code": response.status_code,
        }

    async def _intelligent_link_search(self, event: dict) -> str | None:
        """Usa Perplexity para buscar o link correto de um evento."""
        titulo = event.get("titulo", "") or event.get("nome", "")
        data = event.get("data", "")
        horario = event.get("horario", "")
        local = event.get("local", "")
        categoria = event.get("categoria", "")
        preco = event.get("preco", "")
        descricao = event.get("descricao_enriquecida") or event.get("descricao", "")
        fontes = event.get("fontes", [])

        logger.info(f"Buscando link correto para: {titulo}")

        # Criar agente de busca com Perplexity
        search_agent = Agent(
            name="Link Search Agent",
            model=OpenAIChat(
                id=MODELS["search"],  # perplexity/sonar-pro
                api_key=OPENROUTER_API_KEY,
                base_url=OPENROUTER_BASE_URL,
            ),
            description="Agente especializado em encontrar links oficiais de eventos",
            instructions=[
                "Buscar apenas links OFICIAIS de venda/informa√ß√µes",
                "Priorizar Sympla, Eventbrite, Ticketmaster, site do venue",
                "N√ÉO retornar links gen√©ricos de homepage",
                "Retornar APENAS o URL ou 'NONE' se n√£o encontrar",
            ],
        )

        # Construir prompt com todas as informa√ß√µes dispon√≠veis
        fonte_info = f"\nFontes mencionadas: {', '.join(fontes[:3])}" if fontes else ""
        horario_info = f"\nHor√°rio: {horario}" if horario else ""
        categoria_info = f"\nCategoria: {categoria}" if categoria else ""
        preco_info = f"\nPre√ßo: {preco}" if preco else ""

        prompt = f"""Encontre o link de compra/informa√ß√µes OFICIAL para este evento no Rio de Janeiro:

T√≠tulo: {titulo}
Data: {data}{horario_info}
Local: {local}{categoria_info}{preco_info}
Descri√ß√£o: {descricao[:200]}{fonte_info}

IMPORTANTE:
- Busque o link ESPEC√çFICO deste evento, n√£o a p√°gina principal do local
- Priorize plataformas de venda: Sympla, Eventbrite, Ticketmaster
- Se n√£o encontrar em plataformas, busque no site oficial do venue
- Valide que a data e t√≠tulo correspondem ao evento solicitado

Busque em:
- Sympla (sympla.com.br) - busque pelo t√≠tulo exato
- Eventbrite (eventbrite.com.br) - busque pelo t√≠tulo exato
- Ticketmaster Brasil
- Site oficial do venue/local (ex: bluenoterio.com.br, casadochoro.com.br)
- Instagram oficial do evento/local (apenas se tiver link de venda)

Retorne APENAS o URL completo e v√°lido (come√ßando com http:// ou https://), ou "NONE" se n√£o encontrar nada confi√°vel.
N√ÉO retorne:
- Links gen√©ricos de homepage
- Agregadores de eventos
- Links quebrados
- P√°ginas de busca"""

        try:
            response = search_agent.run(prompt)
            new_link = response.content.strip()

            # Validar resposta
            if new_link and new_link != "NONE" and new_link.startswith("http"):
                logger.info(f"‚úì Link encontrado: {new_link}")
                return new_link
            else:
                logger.warning(f"‚úó Nenhum link v√°lido encontrado para: {titulo}")
                return None

        except Exception as e:
            logger.error(f"Erro na busca inteligente de link: {e}")
            return None

    async def _validate_links(self, events: dict | list) -> dict | list:
        """Valida se os links de eventos s√£o acess√≠veis com retry e busca inteligente."""
        logger.info("Validando links de eventos com retry autom√°tico...")

        # Extrair eventos da estrutura complexa do structured_events.json
        event_list = []
        if isinstance(events, dict):
            # Estrutura: {"eventos_gerais": {"eventos": [...]}, "eventos_locais_especiais": {...}}
            if "eventos_gerais" in events:
                event_list.extend(events["eventos_gerais"].get("eventos", []))

            if "eventos_locais_especiais" in events:
                for local_name, local_events in events["eventos_locais_especiais"].items():
                    if isinstance(local_events, list):
                        # Filtra eventos reais (apenas dicts, ignora __checagem e outros tipos)
                        event_list.extend([e for e in local_events if isinstance(e, dict) and "__checagem" not in e])

            # Fallback para estrutura simples
            if not event_list:
                event_list = events.get("events", [])
        else:
            event_list = events

        # Estat√≠sticas de valida√ß√£o
        stats = {
            "total_links": 0,
            "validated_first_try": 0,
            "validated_after_retry": 0,
            "failed_all_retries": 0,
            "intelligent_searches": 0,
            "links_fixed": 0,
            "no_retry_needed": 0,  # HTTP 404, 403, etc
            "generic_links_detected": 0,  # Links gen√©ricos detectados
        }

        async with httpx.AsyncClient(timeout=HTTP_TIMEOUT, follow_redirects=True) as client:
            for event in event_list:
                link = event.get("link") or event.get("link_ingresso") or event.get("ticket_link")

                if not link:
                    event["link_valid"] = None
                    continue

                # Detectar placeholder "INCOMPLETO" e ir direto para busca inteligente
                if link in ["INCOMPLETO", "incompleto", "/INCOMPLETO", "NONE", "none"]:
                    logger.info(f"‚Üí Link placeholder detectado ({link}), iniciando busca inteligente: {event.get('titulo')}")
                    stats["total_links"] += 1
                    stats["intelligent_searches"] += 1

                    new_link = await self._intelligent_link_search(event)

                    if new_link and new_link not in ["INCOMPLETO", "NONE", "none"]:
                        event["link_original"] = link
                        event["link"] = new_link
                        event["link_updated_by_ai"] = True

                        # Validar novo link (1 tentativa)
                        try:
                            result = await self._validate_single_link(client, new_link, attempt_num=1)
                            event["link_valid"] = result["valid"]
                            event["link_status_code"] = result["status_code"]
                            stats["links_fixed"] += 1
                            logger.info(f"‚úì Link corrigido com sucesso: {new_link}")
                        except Exception as e:
                            event["link_valid"] = False
                            event["link_error"] = f"Novo link falhou: {type(e).__name__}"
                            logger.warning(f"‚úó Novo link tamb√©m falhou: {new_link}")
                    else:
                        event["link_valid"] = False
                        event["link_error"] = "Placeholder sem link v√°lido encontrado"
                        event["requires_manual_link_check"] = True
                        logger.warning(f"‚ö† Nenhum link encontrado para: {event.get('titulo')}")

                    continue

                # Detectar link gen√©rico (p√°gina de busca/categoria) e ir para busca inteligente
                if self._is_generic_link(link):
                    logger.info(f"üö´ Link gen√©rico detectado, iniciando busca inteligente: {link[:80]}...")
                    stats["total_links"] += 1
                    stats["generic_links_detected"] += 1
                    stats["intelligent_searches"] += 1

                    new_link = await self._intelligent_link_search(event)

                    if new_link and not self._is_generic_link(new_link):
                        event["link_original"] = link
                        event["link"] = new_link
                        event["link_updated_by_ai"] = True
                        event["link_was_generic"] = True

                        # Validar novo link (1 tentativa)
                        try:
                            result = await self._validate_single_link(client, new_link, attempt_num=1)
                            event["link_valid"] = result["valid"]
                            event["link_status_code"] = result["status_code"]
                            stats["links_fixed"] += 1
                            logger.info(f"‚úì Link gen√©rico substitu√≠do por link espec√≠fico: {new_link}")
                        except Exception as e:
                            event["link_valid"] = False
                            event["link_error"] = f"Novo link falhou: {type(e).__name__}"
                            logger.warning(f"‚úó Novo link tamb√©m falhou: {new_link}")
                    else:
                        # Nenhum link espec√≠fico encontrado, manter gen√©rico mas marcar
                        event["link_valid"] = False
                        event["link_is_generic"] = True
                        event["link_error"] = "Link gen√©rico - p√°gina de busca/categoria"
                        event["requires_manual_link_check"] = True
                        logger.warning(f"‚ö† Nenhum link espec√≠fico encontrado para: {event.get('titulo')}")

                    continue

                stats["total_links"] += 1
                original_link = link

                try:
                    # Tentar validar com retry autom√°tico
                    result = await self._validate_single_link(client, link, attempt_num=1)
                    event["link_valid"] = result["valid"]
                    event["link_status_code"] = result["status_code"]
                    stats["validated_first_try"] += 1
                    logger.info(f"‚úì Link v√°lido: {link} (status: {result['status_code']})")

                except Exception as e:
                    # Verificar se √© erro que n√£o deve ter retry (404, 403, etc)
                    if isinstance(e, httpx.HTTPStatusError):
                        if e.response.status_code in [404, 403, 401, 410]:
                            # Erros permanentes - n√£o fazer retry
                            event["link_valid"] = False
                            event["link_status_code"] = e.response.status_code
                            event["link_error"] = f"HTTP {e.response.status_code}"
                            stats["no_retry_needed"] += 1
                            logger.warning(f"‚úó Link com erro permanente: {link} ({e.response.status_code})")

                            # Ir direto para busca inteligente
                            stats["intelligent_searches"] += 1
                            new_link = await self._intelligent_link_search(event)

                            if new_link and new_link != original_link:
                                event["link_original"] = original_link
                                event["link"] = new_link
                                event["link_updated_by_ai"] = True

                                # Validar novo link (1 tentativa apenas)
                                try:
                                    result = await self._validate_single_link(client, new_link, attempt_num=1)
                                    event["link_valid"] = result["valid"]
                                    event["link_status_code"] = result["status_code"]
                                    stats["links_fixed"] += 1
                                    logger.info(f"‚úì Link corrigido com sucesso: {new_link}")
                                except Exception:
                                    event["link_valid"] = False
                                    logger.warning(f"‚úó Novo link tamb√©m falhou: {new_link}")

                            continue

                    # Todas as tentativas de retry falharam (timeout, connection error, etc)
                    logger.warning(f"‚úó Todas as {MAX_RETRIES} tentativas falharam para: {link}")
                    logger.warning(f"   Erro: {type(e).__name__}: {e}")

                    event["link_valid"] = False
                    event["link_error"] = f"{type(e).__name__}: {str(e)}"
                    event["link_validation_failed"] = True
                    stats["failed_all_retries"] += 1

                    # Tentar busca inteligente como √∫ltimo recurso
                    logger.info(f"‚Üí Tentando busca inteligente para: {event.get('titulo')}")
                    stats["intelligent_searches"] += 1

                    new_link = await self._intelligent_link_search(event)

                    if new_link and new_link != original_link:
                        event["link_original"] = original_link
                        event["link"] = new_link
                        event["link_updated_by_ai"] = True

                        # Validar novo link (1 tentativa apenas)
                        try:
                            result = await self._validate_single_link(client, new_link, attempt_num=1)
                            event["link_valid"] = result["valid"]
                            event["link_status_code"] = result["status_code"]
                            stats["links_fixed"] += 1
                            logger.info(f"‚úì Link corrigido com sucesso: {new_link}")
                        except Exception as e2:
                            event["link_valid"] = False
                            event["link_error"] = f"Novo link falhou: {type(e2).__name__}"
                            logger.warning(f"‚úó Novo link tamb√©m falhou: {new_link}")
                    else:
                        # Marcar para revis√£o manual
                        event["requires_manual_link_check"] = True
                        logger.warning(f"‚ö† Evento requer revis√£o manual de link: {event.get('titulo')}")

        # Log de estat√≠sticas
        logger.info(f"\n{'='*60}")
        logger.info("üìä Estat√≠sticas de Valida√ß√£o de Links:")
        logger.info(f"  Total de links verificados: {stats['total_links']}")
        logger.info(f"  ‚úì Validados na 1¬™ tentativa: {stats['validated_first_try']}")
        logger.info(f"  ‚úó Falharam ap√≥s todos os retries: {stats['failed_all_retries']}")
        logger.info(f"  ‚úó Erros permanentes (404, 403, etc): {stats['no_retry_needed']}")
        logger.info(f"  üö´ Links gen√©ricos detectados: {stats['generic_links_detected']}")
        logger.info(f"  üîç Buscas inteligentes realizadas: {stats['intelligent_searches']}")
        logger.info(f"  ‚úì Links corrigidos via IA: {stats['links_fixed']}")
        logger.info(f"{'='*60}\n")

        return events

    def _verify_with_llm(self, events: dict | list) -> dict[str, Any]:
        """Usa LLM para verifica√ß√£o inteligente de eventos."""
        logger.info("Verificando eventos com LLM...")

        # Calcular datas e dias da semana para passar ao LLM
        start_date = SEARCH_CONFIG['start_date']
        end_date = SEARCH_CONFIG['end_date']

        # Gerar calend√°rio de s√°bados e domingos no per√≠odo
        weekends = []
        current = start_date
        while current <= end_date:
            weekday_num = current.weekday()  # 5=s√°bado, 6=domingo
            if weekday_num in [5, 6]:
                weekday_name = "s√°bado" if weekday_num == 5 else "domingo"
                weekends.append(f"{current.strftime('%d/%m/%Y')} ({weekday_name})")
            current += timedelta(days=1)

        weekends_text = "\n".join(weekends)

        prompt = f"""
Voc√™ √© um agente de verifica√ß√£o rigoroso. Analise os eventos abaixo e classifique cada um como:
- APROVADO: evento v√°lido e confi√°vel
- REJEITADO: evento que n√£o atende crit√©rios ou informa√ß√µes inconsistentes

EVENTOS PARA VERIFICAR:
{json.dumps(events, indent=2, ensure_ascii=False)}

PER√çODO V√ÅLIDO: {start_date.strftime('%d/%m/%Y')} a {end_date.strftime('%d/%m/%Y')}

S√ÅBADOS E DOMINGOS NO PER√çODO (para valida√ß√£o de eventos ao ar livre):
{weekends_text}

CRIT√âRIOS DE APROVA√á√ÉO:

1. DATA V√ÅLIDA:
   - Deve estar entre {start_date.strftime('%d/%m/%Y')} e {end_date.strftime('%d/%m/%Y')}

2. TEATRO COM√âDIA / STAND-UP:
   - APROVAR: com√©dia adulta, stand-up, humor para adultos, "indicado para maiores de 14/16/18"
   - REJEITAR: apenas se EXPLICITAMENTE infantil ("teatro infantil", "para crian√ßas", "kids", "fam√≠lia")
   - DICA: Se diz "todas as idades mas voltado ao p√∫blico adulto" ‚Üí APROVAR (n√£o √© infantil)

3. EVENTOS AO AR LIVRE:
   - APROVAR: apenas se data for s√°bado OU domingo (use lista acima)
   - REJEITAR: se for segunda, ter√ßa, quarta, quinta ou sexta-feira

4. LINKS:
   - Links gen√©ricos (ex: sympla.com.br, ticketmaster.com.br) ‚Üí N√ÉO rejeitar automaticamente
   - Se link √© de plataforma confi√°vel (Sympla, Eventbrite, Ticketmaster) e outras infos est√£o completas ‚Üí APROVAR com aviso
   - Apenas rejeitar se link for suspeito ou evento n√£o tiver NENHUMA info de compra

5. INFORMA√á√ïES M√çNIMAS:
   - Obrigat√≥rio: t√≠tulo, data, local
   - Pre√ßo e hor√°rio podem ser "Consultar" se outras infos estiverem completas

CRIT√âRIOS DE REJEI√á√ÉO:

- Eventos com data fora do per√≠odo v√°lido
- Teatro EXPLICITAMENTE infantil na categoria com√©dia
- Eventos ao ar livre em dias de SEMANA (segunda a sexta)
- Informa√ß√µes extremamente incompletas (falta t√≠tulo OU data OU local)
- Duplicatas exatas (mesmo t√≠tulo, mesma data, mesmo local)

CRIT√âRIOS DE DUPLICATAS:
- Mesmo evento: mesmo t√≠tulo (ou muito similar >90%), mesma data, mesmo local
- EXCE√á√ÉO: Sess√µes diferentes do MESMO evento em datas diferentes N√ÉO s√£o duplicatas (ex: "Show X" dia 12 e "Show X" dia 13)

TAREFA:
Retorne JSON estruturado:
{{
    "verified_events": [eventos aprovados com descri√ß√£o enriquecida],
    "rejected_events": [eventos rejeitados com motivo claro],
    "warnings": [avisos gerais sobre valida√ß√µes],
    "duplicates_removed": [lista de duplicatas removidas]
}}

IMPORTANTE:
- Para cada evento aprovado, ENRIQUE√áA a descri√ß√£o se ela estiver muito curta
- Para eventos rejeitados, explique CLARAMENTE o motivo
- Seja mais PERMISSIVO com links gen√©ricos de plataformas confi√°veis
- Valide dias da semana usando a lista de s√°bados/domingos fornecida acima
"""

        try:
            response = self.agent.run(prompt)
            content = response.content

            # Tentar extrair JSON da resposta
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                content = content.split("```")[1].split("```")[0].strip()

            verified_data = json.loads(content)
            return verified_data

        except Exception as e:
            logger.error(f"Erro ao verificar com LLM: {e}")
            return {
                "verified_events": [],
                "rejected_events": [],
                "warnings": [f"Erro na verifica√ß√£o: {str(e)}"],
            }

    def get_verification_stats(self, verified_data: dict[str, Any]) -> dict[str, int]:
        """Retorna estat√≠sticas da verifica√ß√£o."""
        return {
            "total_verified": len(verified_data.get("verified_events", [])),
            "total_rejected": len(verified_data.get("rejected_events", [])),
            "total_warnings": len(verified_data.get("warnings", [])),
            "duplicates_removed": len(verified_data.get("duplicates_removed", [])),
        }
