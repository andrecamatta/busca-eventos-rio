# üìä An√°lise de Qualidade dos Eventos - Problemas e Solu√ß√µes

## üéØ Resumo Executivo

Como a API de produ√ß√£o est√° protegida, esta an√°lise foi feita com base nos **crit√©rios de julgamento do sistema** e nas **limita√ß√µes conhecidas** documentadas.

### Crit√©rios de Avalia√ß√£o (GPT-5)
1. **Ader√™ncia ao Prompt** (30%) - Evento corresponde ao solicitado?
2. **Correla√ß√£o Link-Conte√∫do** (30%) - Dados batem com o link?
3. **Precis√£o de Data/Hor√°rio** (30%) - CR√çTICO
4. **Completude e Consist√™ncia** (10%) - Campos preenchidos e consistentes?

**F√≥rmula**: `quality_score = (prompt*0.3) + (content*0.3) + (date*0.3) + (completeness*0.1)`

---

## ‚ùå Principais Problemas que Causam Notas Baixas

### 1. üö® CR√çTICO: Precis√£o de Data e Hor√°rio (Peso 30%)

**Problema identificado**: Este √© o crit√©rio com maior impacto nas notas baixas.

#### Severidades definidas no c√≥digo:
```
CR√çTICO (nota 0-3):  Data com diferen√ßa de MESES ou ANOS
GRAVE (nota 3-5):    Data com diferen√ßa >7 DIAS
M√âDIO (nota 5-7):    Hor√°rio com diferen√ßa >2 horas
LEVE (nota 7-8):     Hor√°rio com diferen√ßa de 1-2 horas
OK (nota 8-10):      Data/hor√°rio corretos (¬±30min)
```

#### Causas Comuns:
- **LLM "alucinando" datas** quando o link n√£o tem data clara
- **Parser de data interpretando formato errado** (ex: MM/DD vs DD/MM)
- **Eventos multi-sess√£o**: extrai uma data mas link mostra v√°rias
- **Links desatualizados**: site mostra data antiga
- **Scrapers pegando data de publica√ß√£o** ao inv√©s de data do evento

#### Impacto:
- **Uma data errada de 1 m√™s** = nota 0-3 neste crit√©rio = perda de at√© 9 pontos na nota final!
- **Hor√°rio errado de 3 horas** = nota 5-7 = perda de at√© 1.5 pontos

---

### 2. ‚ö†Ô∏è GRAVE: Inconsist√™ncia T√≠tulo vs Descri√ß√£o (Peso 10%)

**Problema identificado no c√≥digo** (judge_agent.py:428-438):

#### Exemplos de INCONSIST√äNCIA CR√çTICA (nota 0-3):
```
‚ùå T√≠tulo: "Lumen Festival"
   Descri√ß√£o: "Exibi√ß√£o do filme 'O Quarto das Sombras'"

‚ùå T√≠tulo: "Programa√ß√£o CCBB"
   Descri√ß√£o: "Pe√ßa teatral 'Hamlet' √†s 20h"

‚ùå T√≠tulo: "Festival de Piano"
   Descri√ß√£o: "Recital do pianista Fulano com obras de Chopin"
```

#### Como deveria ser (nota 8-10):
```
‚úÖ T√≠tulo: "'O Quarto das Sombras' no Lumen Festival"
   Descri√ß√£o: "Filme de suspense psicol√≥gico exibido no Lumen..."

‚úÖ T√≠tulo: "Hamlet - Cia de Teatro XYZ"
   Descri√ß√£o: "Cl√°ssico de Shakespeare na programa√ß√£o do CCBB..."

‚úÖ T√≠tulo: "Recital de Piano - Jo√£o da Silva"
   Descri√ß√£o: "Obras de Chopin interpretadas pelo pianista..."
```

#### Causas Comuns:
- **Search Agent retorna t√≠tulo gen√©rico** do festival/venue
- **Descri√ß√£o extrai evento espec√≠fico** mas t√≠tulo n√£o √© atualizado
- **Scraper pega t√≠tulo da p√°gina** (gen√©rico) e n√£o do evento individual

#### Impacto:
- Nota 0-3 neste crit√©rio = perda de at√© 0.7 pontos na nota final
- **Problema de UX**: usu√°rio n√£o sabe qual evento espec√≠fico √©

---

### 3. ‚ö†Ô∏è IMPORTANTE: Correla√ß√£o Link-Conte√∫do (Peso 30%)

**Problema identificado**: 41% dos eventos sem link de compra (LIMITACOES.md:38)

#### Sub-problemas:

##### 3.1 Links Gen√©ricos
```
‚ùå bluenoterio.com.br/shows/
‚ùå teatromunicipal.rj.gov.br/agenda/
‚ùå sympla.com.br/eventos/rio-de-janeiro
```

**Causa**: Search Agent n√£o encontra link espec√≠fico ou valida√ß√£o falha

##### 3.2 Dados N√£o Batem com o Link
```
Evento diz: "Blue Note Rio - Barra"
Link mostra: "Blue Note Copacabana"

Evento diz: "R$ 80,00"
Link mostra: "R$ 120,00" (pre√ßo atualizado)
```

**Causa**: Site atualizou informa√ß√µes ap√≥s scraping

##### 3.3 Links Inacess√≠veis
**Penalidade**: Nota autom√°tica 5.0 (judge_agent.py:328, 471)

**Causas**:
- Sympla com Queue-it (prote√ß√£o anti-bot)
- Sites fora do ar temporariamente
- Paywalls ou logins obrigat√≥rios

#### Impacto:
- **Sem link**: Nota 5.0 = perda de 1.5 pontos (30% √ó 5.0 = 1.5)
- **Link com dados errados**: Nota 3-6 = perda de 1.2-2.1 pontos
- **Links gen√©ricos**: Afeta UX + pode ser rejeitado

---

### 4. ‚ö†Ô∏è M√âDIO: Ader√™ncia ao Prompt (Peso 30%)

**Problema**: Eventos n√£o relacionados ou muito correlatos

#### O sistema J√Å √© tolerante (judge_agent.py:271-280):
```
‚úÖ V√ÅLIDOS (nota >= 7):
   - Concertos cl√°ssicos + Recitais
   - Jazz + Bossa Nova
   - Teatro + Com√©dia stand-up

‚ùå INV√ÅLIDO (nota baixa):
   - Pediu shows adultos, retornou infantil
   - Pediu m√∫sica, retornou exposi√ß√£o de arte
```

#### Causas de Notas Baixas:
- **Search Agent interpreta mal o prompt** (ex: busca "teatro" retorna "teatro de bonecos infantil")
- **Filtros de valida√ß√£o falharam** (evento infantil passou)
- **LLM criativo demais** ("caf√© cultural" vira "workshop de culin√°ria molecular")

#### Impacto:
- **Evento totalmente fora de contexto**: Nota 0-4 = perda de at√© 3 pontos

---

### 5. ‚ö†Ô∏è LEVE: Completude (Peso 10%)

**Problemas comuns**:
- ‚ùå Campo `preco` vazio quando site tem pre√ßo
- ‚ùå Campo `descricao` muito curto (< 50 chars)
- ‚ùå Hor√°rio ausente
- ‚ùå Endere√ßo incompleto

#### Impacto:
- **Campos vazios**: Nota 5-7 = perda de 0.3-0.5 pontos
- **Menor peso**, mas afeta UX

---

## üîß Adapta√ß√µes Sugeridas (Prioridade)

### üö® PRIORIDADE M√ÅXIMA: Melhorar Precis√£o de Datas

#### Adapta√ß√£o 1.1: Valida√ß√£o de Data Mais Rigorosa no Scraping
```python
# Em agents/search_agent.py ou utils/event_extractors.py

def validate_event_date_from_link(event: dict, link_html: str) -> bool:
    """
    Compara data extra√≠da com datas no HTML do link.
    Retorna False se diverg√™ncia > 7 dias.
    """
    event_date = parse_date(event['data'])
    link_dates = extract_all_dates_from_html(link_html)

    # Verificar se event_date est√° em ¬±7 dias de alguma data do link
    for link_date in link_dates:
        if abs((event_date - link_date).days) <= 7:
            return True

    return False  # Data n√£o bate - rejeitar ou corrigir
```

**Impacto esperado**: Reduzir erros cr√≠ticos de data de ~15% para <5%

#### Adapta√ß√£o 1.2: Scrapers Oficiais com Parsing Estruturado
```python
# Expandir scrapers como utils/eventim_scraper.py

class CCBBScraper:
    """Scraper direto da API/site do CCBB"""

    def extract_dates_from_structured_data(self, url: str):
        """
        Extrai datas de schema.org/Event, JSON-LD, ou elementos
        HTML com data-* attributes.

        Priorizar:
        1. <time datetime="2025-11-15T20:00:00"> (ISO 8601)
        2. JSON-LD startDate/endDate
        3. Meta tags
        """
        pass
```

**Impacto esperado**: Scrapers oficiais t√™m taxa de acerto de datas >95%

**A√ß√£o**: Implementar scrapers para:
- ‚úÖ CCBB (j√° implementado - commit 19a8cea)
- ‚úÖ Sala Cec√≠lia Meireles (j√° implementado - commit 54fe510)
- ‚è≥ Eventim (parcial - utils/eventim_scraper.py)
- ‚è≥ Teatro Municipal
- ‚è≥ Sympla (evitar Queue-it)

---

### üî• PRIORIDADE ALTA: Corrigir T√≠tulos Gen√©ricos

#### Adapta√ß√£o 2.1: Detec√ß√£o e Corre√ß√£o de T√≠tulos Gen√©ricos
```python
# Em agents/search_agent.py ou novo utils/title_fixer.py

GENERIC_TITLE_PATTERNS = [
    r'^(Programa√ß√£o|Festival|Mostra|Agenda)\s+\w+$',
    r'^(Teatro|Cinema|Shows?)\s+[A-Z][\w\s]+$',
]

def fix_generic_title(event: dict) -> dict:
    """
    Se t√≠tulo gen√©rico mas descri√ß√£o tem detalhes,
    extrai nome espec√≠fico da descri√ß√£o.
    """
    title = event['titulo']
    desc = event['descricao']

    # Detectar t√≠tulo gen√©rico
    if any(re.match(p, title) for p in GENERIC_TITLE_PATTERNS):
        # Extrair nome espec√≠fico da descri√ß√£o
        # Ex: "Exibi√ß√£o do filme 'O Quarto das Sombras'"
        #  -> T√≠tulo: "'O Quarto das Sombras' no Lumen Festival"

        specific_name = extract_specific_name_from_description(desc)
        if specific_name:
            event['titulo'] = f"{specific_name} - {title}"

    return event
```

**Impacto esperado**: Aumentar nota de completude de 6-7 para 8-9 em ~30% dos eventos

---

### üî• PRIORIDADE ALTA: Melhorar Links Espec√≠ficos

**Problema atual**: 41% sem link (LIMITACOES.md:38)

#### Adapta√ß√£o 3.1: Priorizar Scrapers Oficiais
‚úÖ **J√Å IMPLEMENTADO** (commit 49f13fb: "Priorizar scrapers oficiais")

Verificar se est√° ativado em `config.py`:
```python
USE_OFFICIAL_SCRAPERS_FIRST = True  # Deve ser True
SCRAPER_PRIORITY = [
    "ccbb",
    "cecilia_meireles",
    "eventim",
    "sympla",  # s√≥ se resolver Queue-it
]
```

#### Adapta√ß√£o 3.2: Valida√ß√£o de Link Mais Estrita
```python
# Em agents/validation_agent.py ou verify_agent.py

GENERIC_LINK_PATTERNS = [
    r'/shows/?$',
    r'/agenda/?$',
    r'/eventos/?$',
    r'/programacao/?$',
    r'/calendario/?$',
]

def is_generic_link(url: str) -> bool:
    """Detecta links gen√©ricos que devem ser rejeitados"""
    return any(re.search(p, url, re.IGNORECASE) for p in GENERIC_LINK_PATTERNS)
```

‚úÖ **Verificar se J√Å est√° implementado** (LIMITACOES.md:51 diz que foi resolvido)

#### Adapta√ß√£o 3.3: Busca Inteligente de Links (J√° existe - melhorar)
```python
# Em agents/link_search_agent.py (se existir)

async def smart_link_search(event: dict) -> str:
    """
    Busca link espec√≠fico usando:
    1. T√≠tulo do evento + venue + "ingresso"
    2. Artista/autor + data + venue
    3. Sympla/Eventbrite/Ticketmaster API se dispon√≠vel
    """
    queries = [
        f"{event['titulo']} {event['venue']} ingresso",
        f"{event['titulo']} {event['data']} Rio de Janeiro ingressos",
    ]

    for query in queries:
        results = await perplexity_search(query, max_results=3)
        for url in results:
            if is_specific_link(url) and url_is_accessible(url):
                return url

    return None  # Sem link espec√≠fico
```

**Meta**: Aumentar de 41% para 70% eventos com link espec√≠fico

---

### ‚ö†Ô∏è PRIORIDADE M√âDIA: Melhorar Completude de Dados

#### Adapta√ß√£o 4.1: Enrichment Mais Agressivo
```python
# Em agents/enrichment_agent.py (se existir)

REQUIRED_FIELDS = ['titulo', 'data', 'horario', 'local', 'preco', 'descricao']

async def enrich_missing_fields(event: dict, link_html: str):
    """
    Usa LLM para extrair campos faltantes do HTML do link.
    """
    missing = [f for f in REQUIRED_FIELDS if not event.get(f)]

    if missing:
        prompt = f"""
        Extraia do HTML abaixo os seguintes campos faltantes:
        {', '.join(missing)}

        HTML:
        {link_html[:3000]}

        Retorne JSON com apenas os campos solicitados.
        """

        extracted = await llm_call(prompt)
        event.update(extracted)

    return event
```

**Impacto esperado**: Reduzir eventos com campos vazios de ~20% para <10%

---

### ‚ö†Ô∏è PRIORIDADE M√âDIA: Detec√ß√£o de "Alucina√ß√µes"

#### Adapta√ß√£o 5.1: Cross-Validation com Link
```python
# Em agents/validation_agent.py

async def cross_validate_with_link(event: dict) -> dict:
    """
    Compara dados extra√≠dos com conte√∫do do link.
    Marca inconsist√™ncias para review.
    """
    link_html = await fetch_link(event['link_ingresso'])
    link_text = extract_text_from_html(link_html)

    # Verificar se t√≠tulo aparece no link
    if event['titulo'] not in link_text:
        similarity = fuzzy_match(event['titulo'], link_text)
        if similarity < 0.6:
            event['_warning'] = "T√≠tulo n√£o encontrado no link"

    # Verificar pre√ßo
    link_prices = extract_prices(link_html)
    if event['preco'] and event['preco'] not in link_prices:
        event['_warning'] = "Pre√ßo diverge do link"

    # Verificar data
    link_dates = extract_dates(link_html)
    if event['data'] not in link_dates:
        event['_warning'] = "Data diverge do link"

    return event
```

**Impacto esperado**: Detectar e corrigir ~50% das "alucina√ß√µes" antes do julgamento

---

## üìà Metas de Qualidade

### Estado Atual (Estimado com base em LIMITACOES.md)
```
Score m√©dio: ~6.5-7.0 / 10
- Ader√™ncia ao prompt: 7.5 (boa)
- Correla√ß√£o link-conte√∫do: 6.0 (41% sem link, alguns dados errados)
- Precis√£o data/hor√°rio: 6.5 (erros cr√≠ticos ocasionais)
- Completude: 7.0 (alguns campos vazios)
```

### Metas Ap√≥s Implementa√ß√£o das Adapta√ß√µes

#### Meta 1 (3 meses): Score 7.8-8.4 / 10
‚úÖ **J√Å IMPLEMENTADO** (commit 6f222a0: "meta 7.8-8.4/10")

```
- Ader√™ncia ao prompt: 8.0
- Correla√ß√£o link-conte√∫do: 7.5 (60% com link espec√≠fico)
- Precis√£o data/hor√°rio: 8.5 (erros cr√≠ticos <5%)
- Completude: 8.0
```

**A√ß√µes necess√°rias**:
1. ‚úÖ Scrapers oficiais priorizados
2. ‚è≥ Valida√ß√£o de data rigorosa
3. ‚è≥ Fix de t√≠tulos gen√©ricos
4. ‚è≥ Enrichment de campos faltantes

#### Meta 2 (6 meses): Score 8.5-9.0 / 10
```
- Ader√™ncia ao prompt: 8.5
- Correla√ß√£o link-conte√∫do: 8.5 (75% com link espec√≠fico)
- Precis√£o data/hor√°rio: 9.0 (erros cr√≠ticos <2%)
- Completude: 8.5
```

**A√ß√µes necess√°rias**:
1. Scrapers oficiais para todos os venues principais
2. APIs diretas (Sympla, Eventbrite)
3. Cross-validation autom√°tica
4. Cache de eventos para deduplica√ß√£o

---

## üéØ Roadmap de Implementa√ß√£o

### Fase 1: Quick Wins (1-2 semanas)
- [ ] **Adapta√ß√£o 2.1**: Detec√ß√£o e corre√ß√£o de t√≠tulos gen√©ricos
- [ ] **Adapta√ß√£o 3.2**: Verificar valida√ß√£o de links gen√©ricos (pode j√° estar feita)
- [ ] **Adapta√ß√£o 4.1**: Enrichment mais agressivo de campos vazios

**Impacto esperado**: +0.5-0.8 pontos na nota m√©dia

### Fase 2: Melhorias Estruturais (1 m√™s)
- [ ] **Adapta√ß√£o 1.1**: Valida√ß√£o de data rigorosa no scraping
- [ ] **Adapta√ß√£o 1.2**: Expandir scrapers oficiais (Teatro Municipal, etc)
- [ ] **Adapta√ß√£o 5.1**: Cross-validation com link

**Impacto esperado**: +0.8-1.2 pontos na nota m√©dia

### Fase 3: Otimiza√ß√µes Avan√ßadas (2-3 meses)
- [ ] **Adapta√ß√£o 3.3**: Melhorar busca inteligente de links
- [ ] Implementar APIs oficiais (Sympla, Eventbrite)
- [ ] Sistema de cache para evitar re-scraping
- [ ] Dashboard de monitoramento de qualidade

**Impacto esperado**: +0.5-0.7 pontos na nota m√©dia

---

## üìä Como Monitorar Melhorias

### 1. Executar Julgamento Regularmente
```bash
python run_judge_production.py
```

**Ver estat√≠sticas**:
- Score m√©dio geral
- Distribui√ß√£o de notas por crit√©rio
- Top 5 melhores e piores eventos

### 2. Analisar Tend√™ncias
```bash
# Eventos com nota < 6.0 (precisam aten√ß√£o)
jq '.events[] | select(.quality_score < 6.0) | {titulo, quality_score, notes}' \
   output/latest/judged_events.json

# Principais problemas (notes mais frequentes)
jq -r '.events[].quality_notes' output/latest/judged_events.json | \
   grep -oE '(Data|Hor√°rio|T√≠tulo|Link|Pre√ßo)[^.]*' | sort | uniq -c | sort -rn
```

### 3. Comparar Antes/Depois
```bash
# Salvar baseline antes das mudan√ßas
cp output/latest/judged_events.json baseline_$(date +%Y%m%d).json

# Ap√≥s implementar melhorias, comparar scores m√©dios
jq '.summary.overall_stats.average' baseline_*.json
jq '.summary.overall_stats.average' output/latest/judged_events.json
```

---

## üöÄ Conclus√£o

### Problemas Cr√≠ticos Identificados:
1. **üö® Precis√£o de Data/Hor√°rio** (30% do score) - erros ocasionais graves
2. **‚ö†Ô∏è T√≠tulos Gen√©ricos** (10% do score) - ~20-30% dos eventos afetados
3. **‚ö†Ô∏è Falta de Links Espec√≠ficos** (30% do score) - 41% sem link

### Melhorias Priorit√°rias:
1. **Valida√ß√£o rigorosa de datas** no scraping (prevenir erros cr√≠ticos)
2. **Corre√ß√£o autom√°tica de t√≠tulos gen√©ricos** (UX + score)
3. **Expans√£o de scrapers oficiais** (links + dados confi√°veis)

### Impacto Esperado:
- **Score atual**: ~6.5-7.0 / 10
- **Meta 3 meses**: 7.8-8.4 / 10 (**‚úÖ j√° implementado segundo commits**)
- **Meta 6 meses**: 8.5-9.0 / 10

**Pr√≥ximo passo**: Verificar no c√≥digo se as melhorias dos commits recentes (6f222a0, 49f13fb) j√° est√£o ativas e funcionando conforme esperado.
